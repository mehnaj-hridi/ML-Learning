{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e11a7cbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Libraries imported\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"✅ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b05a8682",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Load dataset \n",
        "df = pd.read_csv(\"email_phishing_dataset_FINAL.csv\")\n",
        "\n",
        "print(\"✅ Dataset loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "21906d9d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email_subject_len</th>\n",
              "      <th>email_has_urgent_keyword</th>\n",
              "      <th>email_from_domain</th>\n",
              "      <th>web_url</th>\n",
              "      <th>web_url_len</th>\n",
              "      <th>web_ip_add</th>\n",
              "      <th>web_geo_loc</th>\n",
              "      <th>web_tld</th>\n",
              "      <th>web_who_is</th>\n",
              "      <th>web_https</th>\n",
              "      <th>...</th>\n",
              "      <th>content_entropy</th>\n",
              "      <th>domain_trust_score</th>\n",
              "      <th>email_domain_matches_url</th>\n",
              "      <th>email_url_domain_similarity</th>\n",
              "      <th>content_num_forms</th>\n",
              "      <th>content_num_inputs</th>\n",
              "      <th>content_num_scripts</th>\n",
              "      <th>content_suspicious_keywords</th>\n",
              "      <th>semantic_coherence_score</th>\n",
              "      <th>brand_consistency_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>spamassassin.zones.apache.org</td>\n",
              "      <td>http://tools.ietf.org/html/rfc1583</td>\n",
              "      <td>34</td>\n",
              "      <td>30.180.42.35</td>\n",
              "      <td>United States</td>\n",
              "      <td>org</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>4.620961</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.043153</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>gmail.com&gt;</td>\n",
              "      <td>http://www.quickfixgolf.com</td>\n",
              "      <td>27</td>\n",
              "      <td>150.66.16.42</td>\n",
              "      <td>Japan</td>\n",
              "      <td>com</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>4.742243</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.081125</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>telefonica.net&gt;</td>\n",
              "      <td>http://www.lvnazarene.org</td>\n",
              "      <td>25</td>\n",
              "      <td>180.123.185.229</td>\n",
              "      <td>China</td>\n",
              "      <td>org</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>4.663432</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>gmail.com&gt;</td>\n",
              "      <td>http://hatchersmartialarts.homestead.com/front...</td>\n",
              "      <td>51</td>\n",
              "      <td>46.97.122.170</td>\n",
              "      <td>Romania</td>\n",
              "      <td>com</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>4.971977</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.071720</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>luebeck.de&gt;</td>\n",
              "      <td>http://www.gabile.com/</td>\n",
              "      <td>22</td>\n",
              "      <td>94.145.85.24</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>com</td>\n",
              "      <td>incomplete</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>4.338266</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   email_subject_len  email_has_urgent_keyword              email_from_domain  \\\n",
              "0                 32                         0  spamassassin.zones.apache.org   \n",
              "1                 46                         0                     gmail.com>   \n",
              "2                 21                         0                telefonica.net>   \n",
              "3                 99                         1                     gmail.com>   \n",
              "4                 72                         1                    luebeck.de>   \n",
              "\n",
              "                                             web_url  web_url_len  \\\n",
              "0                 http://tools.ietf.org/html/rfc1583           34   \n",
              "1                        http://www.quickfixgolf.com           27   \n",
              "2                          http://www.lvnazarene.org           25   \n",
              "3  http://hatchersmartialarts.homestead.com/front...           51   \n",
              "4                             http://www.gabile.com/           22   \n",
              "\n",
              "        web_ip_add    web_geo_loc web_tld  web_who_is web_https  ...  \\\n",
              "0     30.180.42.35  United States     org    complete       yes  ...   \n",
              "1     150.66.16.42          Japan     com    complete       yes  ...   \n",
              "2  180.123.185.229          China     org    complete       yes  ...   \n",
              "3    46.97.122.170        Romania     com    complete       yes  ...   \n",
              "4     94.145.85.24        Denmark     com  incomplete        no  ...   \n",
              "\n",
              "   content_entropy  domain_trust_score email_domain_matches_url  \\\n",
              "0         4.620961                 0.8                        0   \n",
              "1         4.742243                 0.8                        0   \n",
              "2         4.663432                 0.8                        0   \n",
              "3         4.971977                 0.8                        0   \n",
              "4         4.338266                 0.4                        0   \n",
              "\n",
              "   email_url_domain_similarity  content_num_forms  content_num_inputs  \\\n",
              "0                     0.411765                  0                   0   \n",
              "1                     0.500000                  0                   0   \n",
              "2                     0.400000                  0                   0   \n",
              "3                     0.466667                  0                   1   \n",
              "4                     0.357143                  0                   1   \n",
              "\n",
              "   content_num_scripts  content_suspicious_keywords  semantic_coherence_score  \\\n",
              "0                    5                            0                  0.043153   \n",
              "1                    2                            0                  0.081125   \n",
              "2                    2                            0                  0.000000   \n",
              "3                    2                            2                  0.071720   \n",
              "4                   24                            3                  0.000000   \n",
              "\n",
              "   brand_consistency_score  \n",
              "0                      0.5  \n",
              "1                      0.5  \n",
              "2                      0.5  \n",
              "3                      0.5  \n",
              "4                      0.5  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "70076567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (8000, 39)\n"
          ]
        }
      ],
      "source": [
        "# Dataset shape\n",
        "print(\"Dataset shape:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "871646f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8000 entries, 0 to 7999\n",
            "Data columns (total 39 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   email_subject_len            8000 non-null   int64  \n",
            " 1   email_has_urgent_keyword     8000 non-null   int64  \n",
            " 2   email_from_domain            7822 non-null   object \n",
            " 3   web_url                      8000 non-null   object \n",
            " 4   web_url_len                  8000 non-null   int64  \n",
            " 5   web_ip_add                   8000 non-null   object \n",
            " 6   web_geo_loc                  8000 non-null   object \n",
            " 7   web_tld                      8000 non-null   object \n",
            " 8   web_who_is                   8000 non-null   object \n",
            " 9   web_https                    8000 non-null   object \n",
            " 10  web_js_len                   8000 non-null   float64\n",
            " 11  web_js_obf_len               8000 non-null   float64\n",
            " 12  web_content                  8000 non-null   object \n",
            " 13  domain_age                   5668 non-null   float64\n",
            " 14  final_label                  8000 non-null   int64  \n",
            " 15  js_obfuscation_ratio         8000 non-null   float64\n",
            " 16  url_has_ip                   8000 non-null   int64  \n",
            " 17  url_num_dots                 8000 non-null   int64  \n",
            " 18  url_num_hyphens              8000 non-null   int64  \n",
            " 19  url_num_underscores          8000 non-null   int64  \n",
            " 20  url_num_slashes              8000 non-null   int64  \n",
            " 21  url_num_queries              8000 non-null   int64  \n",
            " 22  url_num_ampersands           8000 non-null   int64  \n",
            " 23  url_suspicious_chars         8000 non-null   int64  \n",
            " 24  domain_num_subdomains        8000 non-null   int64  \n",
            " 25  domain_contains_numbers      8000 non-null   int64  \n",
            " 26  domain_suspicious_tld        8000 non-null   int64  \n",
            " 27  url_entropy                  8000 non-null   float64\n",
            " 28  domain_entropy               8000 non-null   float64\n",
            " 29  content_entropy              8000 non-null   float64\n",
            " 30  domain_trust_score           8000 non-null   float64\n",
            " 31  email_domain_matches_url     8000 non-null   int64  \n",
            " 32  email_url_domain_similarity  8000 non-null   float64\n",
            " 33  content_num_forms            8000 non-null   int64  \n",
            " 34  content_num_inputs           8000 non-null   int64  \n",
            " 35  content_num_scripts          8000 non-null   int64  \n",
            " 36  content_suspicious_keywords  8000 non-null   int64  \n",
            " 37  semantic_coherence_score     8000 non-null   float64\n",
            " 38  brand_consistency_score      8000 non-null   float64\n",
            "dtypes: float64(11), int64(20), object(8)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Check data types\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bef02df9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after dropping email_from_domain missing: (7822, 39)\n"
          ]
        }
      ],
      "source": [
        "# email_from_domain missing values\n",
        "df = df.dropna(subset=['email_from_domain'])\n",
        "\n",
        "print(\"Shape after dropping email_from_domain missing:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fcfcd926",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing domain_age after handling: 0\n"
          ]
        }
      ],
      "source": [
        "# Create missingness indicator\n",
        "df['domain_age_missing'] = df['domain_age'].isnull().astype(int)\n",
        "\n",
        "# Impute missing domain_age with 0 (unknown/new domain)\n",
        "df['domain_age'] = df['domain_age'].fillna(0)\n",
        "\n",
        "print(\"Missing domain_age after handling:\", df['domain_age'].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f776505e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final dataset shape: (7822, 40)\n",
            "\n",
            "Any remaining missing values?\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal dataset shape:\", df.shape)\n",
        "print(\"\\nAny remaining missing values?\")\n",
        "print(df.isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "69bdb5d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7822 entries, 0 to 7999\n",
            "Data columns (total 40 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   email_subject_len            7822 non-null   int64  \n",
            " 1   email_has_urgent_keyword     7822 non-null   int64  \n",
            " 2   email_from_domain            7822 non-null   object \n",
            " 3   web_url                      7822 non-null   object \n",
            " 4   web_url_len                  7822 non-null   int64  \n",
            " 5   web_ip_add                   7822 non-null   object \n",
            " 6   web_geo_loc                  7822 non-null   object \n",
            " 7   web_tld                      7822 non-null   object \n",
            " 8   web_who_is                   7822 non-null   object \n",
            " 9   web_https                    7822 non-null   object \n",
            " 10  web_js_len                   7822 non-null   float64\n",
            " 11  web_js_obf_len               7822 non-null   float64\n",
            " 12  web_content                  7822 non-null   object \n",
            " 13  domain_age                   7822 non-null   float64\n",
            " 14  final_label                  7822 non-null   int64  \n",
            " 15  js_obfuscation_ratio         7822 non-null   float64\n",
            " 16  url_has_ip                   7822 non-null   int64  \n",
            " 17  url_num_dots                 7822 non-null   int64  \n",
            " 18  url_num_hyphens              7822 non-null   int64  \n",
            " 19  url_num_underscores          7822 non-null   int64  \n",
            " 20  url_num_slashes              7822 non-null   int64  \n",
            " 21  url_num_queries              7822 non-null   int64  \n",
            " 22  url_num_ampersands           7822 non-null   int64  \n",
            " 23  url_suspicious_chars         7822 non-null   int64  \n",
            " 24  domain_num_subdomains        7822 non-null   int64  \n",
            " 25  domain_contains_numbers      7822 non-null   int64  \n",
            " 26  domain_suspicious_tld        7822 non-null   int64  \n",
            " 27  url_entropy                  7822 non-null   float64\n",
            " 28  domain_entropy               7822 non-null   float64\n",
            " 29  content_entropy              7822 non-null   float64\n",
            " 30  domain_trust_score           7822 non-null   float64\n",
            " 31  email_domain_matches_url     7822 non-null   int64  \n",
            " 32  email_url_domain_similarity  7822 non-null   float64\n",
            " 33  content_num_forms            7822 non-null   int64  \n",
            " 34  content_num_inputs           7822 non-null   int64  \n",
            " 35  content_num_scripts          7822 non-null   int64  \n",
            " 36  content_suspicious_keywords  7822 non-null   int64  \n",
            " 37  semantic_coherence_score     7822 non-null   float64\n",
            " 38  brand_consistency_score      7822 non-null   float64\n",
            " 39  domain_age_missing           7822 non-null   int64  \n",
            "dtypes: float64(11), int64(21), object(8)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1fd1daab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoding complete\n",
            "Final shape: (7822, 37)\n"
          ]
        }
      ],
      "source": [
        "# ENCODING NON-NUMERICAL FEATURES\n",
        "\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# 1️⃣ email_from_domain → frequency encoding\n",
        "domain_freq = df_encoded['email_from_domain'].value_counts(normalize=True)\n",
        "df_encoded['email_domain_freq'] = df_encoded['email_from_domain'].map(domain_freq)\n",
        "df_encoded['email_domain_freq'] = df_encoded['email_domain_freq'].fillna(0)\n",
        "df_encoded.drop(['email_from_domain'], axis=1, inplace=True)\n",
        "\n",
        "# 2️⃣ web_geo_loc → frequency encoding\n",
        "geo_freq = df_encoded['web_geo_loc'].value_counts(normalize=True)\n",
        "df_encoded['geo_freq'] = df_encoded['web_geo_loc'].map(geo_freq).fillna(0)\n",
        "df_encoded.drop(['web_geo_loc'], axis=1, inplace=True)\n",
        "\n",
        "# 3️⃣ web_tld → trust score\n",
        "trusted_tlds = ['com', 'org', 'net', 'edu', 'gov']\n",
        "df_encoded['tld_trust_score'] = df_encoded['web_tld'].apply(\n",
        "    lambda x: 1.0 if x in trusted_tlds else 0.0\n",
        ")\n",
        "df_encoded.drop(['web_tld'], axis=1, inplace=True)\n",
        "\n",
        "# 4️⃣ web_who_is → binary\n",
        "df_encoded['web_who_is'] = df_encoded['web_who_is'].map({'complete': 1, 'incomplete': 0})\n",
        "\n",
        "# 5️⃣ web_https → binary\n",
        "df_encoded['web_https'] = df_encoded['web_https'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# 6️⃣ Drop noisy features\n",
        "df_encoded.drop(['web_url', 'web_ip_add', 'web_content'], axis=1, inplace=True)\n",
        "\n",
        "print(\"✅ Encoding complete\")\n",
        "print(\"Final shape:\", df_encoded.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6005af2f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email_subject_len</th>\n",
              "      <th>email_has_urgent_keyword</th>\n",
              "      <th>email_from_domain</th>\n",
              "      <th>web_url</th>\n",
              "      <th>web_url_len</th>\n",
              "      <th>web_ip_add</th>\n",
              "      <th>web_geo_loc</th>\n",
              "      <th>web_tld</th>\n",
              "      <th>web_who_is</th>\n",
              "      <th>web_https</th>\n",
              "      <th>...</th>\n",
              "      <th>domain_trust_score</th>\n",
              "      <th>email_domain_matches_url</th>\n",
              "      <th>email_url_domain_similarity</th>\n",
              "      <th>content_num_forms</th>\n",
              "      <th>content_num_inputs</th>\n",
              "      <th>content_num_scripts</th>\n",
              "      <th>content_suspicious_keywords</th>\n",
              "      <th>semantic_coherence_score</th>\n",
              "      <th>brand_consistency_score</th>\n",
              "      <th>domain_age_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>spamassassin.zones.apache.org</td>\n",
              "      <td>http://tools.ietf.org/html/rfc1583</td>\n",
              "      <td>34</td>\n",
              "      <td>30.180.42.35</td>\n",
              "      <td>United States</td>\n",
              "      <td>org</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.043153</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>gmail.com&gt;</td>\n",
              "      <td>http://www.quickfixgolf.com</td>\n",
              "      <td>27</td>\n",
              "      <td>150.66.16.42</td>\n",
              "      <td>Japan</td>\n",
              "      <td>com</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.081125</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>telefonica.net&gt;</td>\n",
              "      <td>http://www.lvnazarene.org</td>\n",
              "      <td>25</td>\n",
              "      <td>180.123.185.229</td>\n",
              "      <td>China</td>\n",
              "      <td>org</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>gmail.com&gt;</td>\n",
              "      <td>http://hatchersmartialarts.homestead.com/front...</td>\n",
              "      <td>51</td>\n",
              "      <td>46.97.122.170</td>\n",
              "      <td>Romania</td>\n",
              "      <td>com</td>\n",
              "      <td>complete</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.071720</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>luebeck.de&gt;</td>\n",
              "      <td>http://www.gabile.com/</td>\n",
              "      <td>22</td>\n",
              "      <td>94.145.85.24</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>com</td>\n",
              "      <td>incomplete</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   email_subject_len  email_has_urgent_keyword              email_from_domain  \\\n",
              "0                 32                         0  spamassassin.zones.apache.org   \n",
              "1                 46                         0                     gmail.com>   \n",
              "2                 21                         0                telefonica.net>   \n",
              "3                 99                         1                     gmail.com>   \n",
              "4                 72                         1                    luebeck.de>   \n",
              "\n",
              "                                             web_url  web_url_len  \\\n",
              "0                 http://tools.ietf.org/html/rfc1583           34   \n",
              "1                        http://www.quickfixgolf.com           27   \n",
              "2                          http://www.lvnazarene.org           25   \n",
              "3  http://hatchersmartialarts.homestead.com/front...           51   \n",
              "4                             http://www.gabile.com/           22   \n",
              "\n",
              "        web_ip_add    web_geo_loc web_tld  web_who_is web_https  ...  \\\n",
              "0     30.180.42.35  United States     org    complete       yes  ...   \n",
              "1     150.66.16.42          Japan     com    complete       yes  ...   \n",
              "2  180.123.185.229          China     org    complete       yes  ...   \n",
              "3    46.97.122.170        Romania     com    complete       yes  ...   \n",
              "4     94.145.85.24        Denmark     com  incomplete        no  ...   \n",
              "\n",
              "   domain_trust_score  email_domain_matches_url email_url_domain_similarity  \\\n",
              "0                 0.8                         0                    0.411765   \n",
              "1                 0.8                         0                    0.500000   \n",
              "2                 0.8                         0                    0.400000   \n",
              "3                 0.8                         0                    0.466667   \n",
              "4                 0.4                         0                    0.357143   \n",
              "\n",
              "   content_num_forms  content_num_inputs  content_num_scripts  \\\n",
              "0                  0                   0                    5   \n",
              "1                  0                   0                    2   \n",
              "2                  0                   0                    2   \n",
              "3                  0                   1                    2   \n",
              "4                  0                   1                   24   \n",
              "\n",
              "   content_suspicious_keywords  semantic_coherence_score  \\\n",
              "0                            0                  0.043153   \n",
              "1                            0                  0.081125   \n",
              "2                            0                  0.000000   \n",
              "3                            2                  0.071720   \n",
              "4                            3                  0.000000   \n",
              "\n",
              "   brand_consistency_score  domain_age_missing  \n",
              "0                      0.5                   0  \n",
              "1                      0.5                   0  \n",
              "2                      0.5                   0  \n",
              "3                      0.5                   0  \n",
              "4                      0.5                   0  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4023d2e7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email_subject_len</th>\n",
              "      <th>email_has_urgent_keyword</th>\n",
              "      <th>web_url_len</th>\n",
              "      <th>web_who_is</th>\n",
              "      <th>web_https</th>\n",
              "      <th>web_js_len</th>\n",
              "      <th>web_js_obf_len</th>\n",
              "      <th>domain_age</th>\n",
              "      <th>final_label</th>\n",
              "      <th>js_obfuscation_ratio</th>\n",
              "      <th>...</th>\n",
              "      <th>content_num_forms</th>\n",
              "      <th>content_num_inputs</th>\n",
              "      <th>content_num_scripts</th>\n",
              "      <th>content_suspicious_keywords</th>\n",
              "      <th>semantic_coherence_score</th>\n",
              "      <th>brand_consistency_score</th>\n",
              "      <th>domain_age_missing</th>\n",
              "      <th>email_domain_freq</th>\n",
              "      <th>geo_freq</th>\n",
              "      <th>tld_trust_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11168.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.043153</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.424572</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9692.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.081125</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.071976</td>\n",
              "      <td>0.057658</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>44.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2344.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006009</td>\n",
              "      <td>0.094861</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>84.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10335.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.071720</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.071976</td>\n",
              "      <td>0.002046</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>837.0</td>\n",
              "      <td>460.35</td>\n",
              "      <td>7421.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.549344</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.004858</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   email_subject_len  email_has_urgent_keyword  web_url_len  web_who_is  \\\n",
              "0                 32                         0           34           1   \n",
              "1                 46                         0           27           1   \n",
              "2                 21                         0           25           1   \n",
              "3                 99                         1           51           1   \n",
              "4                 72                         1           22           0   \n",
              "\n",
              "   web_https  web_js_len  web_js_obf_len  domain_age  final_label  \\\n",
              "0          1       137.0            0.00     11168.0            0   \n",
              "1          1        94.0            0.00      9692.0            0   \n",
              "2          1        44.5            0.00      2344.0            0   \n",
              "3          1        84.5            0.00     10335.0            0   \n",
              "4          0       837.0          460.35      7421.0            1   \n",
              "\n",
              "   js_obfuscation_ratio  ...  content_num_forms  content_num_inputs  \\\n",
              "0              0.000000  ...                  0                   0   \n",
              "1              0.000000  ...                  0                   0   \n",
              "2              0.000000  ...                  0                   0   \n",
              "3              0.000000  ...                  0                   1   \n",
              "4              0.549344  ...                  0                   1   \n",
              "\n",
              "   content_num_scripts  content_suspicious_keywords  semantic_coherence_score  \\\n",
              "0                    5                            0                  0.043153   \n",
              "1                    2                            0                  0.081125   \n",
              "2                    2                            0                  0.000000   \n",
              "3                    2                            2                  0.071720   \n",
              "4                   24                            3                  0.000000   \n",
              "\n",
              "   brand_consistency_score  domain_age_missing  email_domain_freq  geo_freq  \\\n",
              "0                      0.5                   0           0.001278  0.424572   \n",
              "1                      0.5                   0           0.071976  0.057658   \n",
              "2                      0.5                   0           0.006009  0.094861   \n",
              "3                      0.5                   0           0.071976  0.002046   \n",
              "4                      0.5                   0           0.000128  0.004858   \n",
              "\n",
              "   tld_trust_score  \n",
              "0              1.0  \n",
              "1              1.0  \n",
              "2              1.0  \n",
              "3              1.0  \n",
              "4              1.0  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "37ddf1eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   email_subject_len  email_has_urgent_keyword  web_url_len  web_who_is  \\\n",
            "0                 32                         0           34           1   \n",
            "1                 46                         0           27           1   \n",
            "2                 21                         0           25           1   \n",
            "3                 99                         1           51           1   \n",
            "4                 72                         1           22           0   \n",
            "\n",
            "   web_https  web_js_len  web_js_obf_len  domain_age  final_label  \\\n",
            "0          1       137.0            0.00     11168.0            0   \n",
            "1          1        94.0            0.00      9692.0            0   \n",
            "2          1        44.5            0.00      2344.0            0   \n",
            "3          1        84.5            0.00     10335.0            0   \n",
            "4          0       837.0          460.35      7421.0            1   \n",
            "\n",
            "   js_obfuscation_ratio  ...  content_num_forms  content_num_inputs  \\\n",
            "0              0.000000  ...                  0                   0   \n",
            "1              0.000000  ...                  0                   0   \n",
            "2              0.000000  ...                  0                   0   \n",
            "3              0.000000  ...                  0                   1   \n",
            "4              0.549344  ...                  0                   1   \n",
            "\n",
            "   content_num_scripts  content_suspicious_keywords  semantic_coherence_score  \\\n",
            "0                    5                            0                  0.043153   \n",
            "1                    2                            0                  0.081125   \n",
            "2                    2                            0                  0.000000   \n",
            "3                    2                            2                  0.071720   \n",
            "4                   24                            3                  0.000000   \n",
            "\n",
            "   brand_consistency_score  domain_age_missing  email_domain_freq  geo_freq  \\\n",
            "0                      0.5                   0           0.001278  0.424572   \n",
            "1                      0.5                   0           0.071976  0.057658   \n",
            "2                      0.5                   0           0.006009  0.094861   \n",
            "3                      0.5                   0           0.071976  0.002046   \n",
            "4                      0.5                   0           0.000128  0.004858   \n",
            "\n",
            "   tld_trust_score  \n",
            "0              1.0  \n",
            "1              1.0  \n",
            "2              1.0  \n",
            "3              1.0  \n",
            "4              1.0  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_encoded.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0a10aed7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6257, 36) (1565, 36)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_encoded.drop('final_label', axis=1)\n",
        "y = df_encoded['final_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2858953b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set class distribution:\n",
            "final_label\n",
            "0    3200\n",
            "1    3057\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test set class distribution:\n",
            "final_label\n",
            "0    800\n",
            "1    765\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count classes in training set\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Training set class distribution:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(\"\\nTest set class distribution:\")\n",
        "print(y_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "08ed7e54",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f072991a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaled Training Data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email_subject_len</th>\n",
              "      <th>email_has_urgent_keyword</th>\n",
              "      <th>web_url_len</th>\n",
              "      <th>web_who_is</th>\n",
              "      <th>web_https</th>\n",
              "      <th>web_js_len</th>\n",
              "      <th>web_js_obf_len</th>\n",
              "      <th>domain_age</th>\n",
              "      <th>js_obfuscation_ratio</th>\n",
              "      <th>url_has_ip</th>\n",
              "      <th>...</th>\n",
              "      <th>content_num_forms</th>\n",
              "      <th>content_num_inputs</th>\n",
              "      <th>content_num_scripts</th>\n",
              "      <th>content_suspicious_keywords</th>\n",
              "      <th>semantic_coherence_score</th>\n",
              "      <th>brand_consistency_score</th>\n",
              "      <th>domain_age_missing</th>\n",
              "      <th>email_domain_freq</th>\n",
              "      <th>geo_freq</th>\n",
              "      <th>tld_trust_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.136842</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.126354</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.322002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.098246</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003610</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.180307</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.087719</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021661</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.539515</td>\n",
              "      <td>0.317010</td>\n",
              "      <td>0.035365</td>\n",
              "      <td>0.584526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.782408</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.069277</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.070175</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.212996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950474</td>\n",
              "      <td>0.934189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.978669</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.223506</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029819</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.189474</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119134</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.206650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007117</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   email_subject_len  email_has_urgent_keyword  web_url_len  web_who_is  \\\n",
              "0           0.136842                       1.0     0.126354         1.0   \n",
              "1           0.098246                       1.0     0.003610         1.0   \n",
              "2           0.087719                       0.0     0.021661         0.0   \n",
              "3           0.070175                       1.0     0.212996         0.0   \n",
              "4           0.189474                       0.0     0.119134         1.0   \n",
              "\n",
              "   web_https  web_js_len  web_js_obf_len  domain_age  js_obfuscation_ratio  \\\n",
              "0        1.0    0.152207        0.000000    0.547386              0.000000   \n",
              "1        1.0    0.180307        0.000000    0.538528              0.000000   \n",
              "2        0.0    0.539515        0.317010    0.035365              0.584526   \n",
              "3        1.0    0.950474        0.934189    0.000000              0.978669   \n",
              "4        1.0    0.206650        0.000000    0.014252              0.000000   \n",
              "\n",
              "   url_has_ip  ...  content_num_forms  content_num_inputs  \\\n",
              "0         0.0  ...                0.0            0.142857   \n",
              "1         0.0  ...                0.0            0.000000   \n",
              "2         0.0  ...                0.0            0.142857   \n",
              "3         0.0  ...                0.0            0.285714   \n",
              "4         0.0  ...                0.0            0.000000   \n",
              "\n",
              "   content_num_scripts  content_suspicious_keywords  semantic_coherence_score  \\\n",
              "0             0.000000                         0.25                  0.322002   \n",
              "1             0.083333                         0.50                  0.000000   \n",
              "2             0.333333                         0.25                  0.782408   \n",
              "3             0.541667                         0.75                  0.223506   \n",
              "4             0.083333                         0.75                  0.000000   \n",
              "\n",
              "   brand_consistency_score  domain_age_missing  email_domain_freq  geo_freq  \\\n",
              "0                      1.0                 0.0           1.000000  1.000000   \n",
              "1                      1.0                 0.0           1.000000  1.000000   \n",
              "2                      1.0                 0.0           0.000000  0.069277   \n",
              "3                      1.0                 1.0           0.000000  0.029819   \n",
              "4                      1.0                 0.0           0.007117  1.000000   \n",
              "\n",
              "   tld_trust_score  \n",
              "0              1.0  \n",
              "1              0.0  \n",
              "2              1.0  \n",
              "3              1.0  \n",
              "4              1.0  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Scaled Test Data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email_subject_len</th>\n",
              "      <th>email_has_urgent_keyword</th>\n",
              "      <th>web_url_len</th>\n",
              "      <th>web_who_is</th>\n",
              "      <th>web_https</th>\n",
              "      <th>web_js_len</th>\n",
              "      <th>web_js_obf_len</th>\n",
              "      <th>domain_age</th>\n",
              "      <th>js_obfuscation_ratio</th>\n",
              "      <th>url_has_ip</th>\n",
              "      <th>...</th>\n",
              "      <th>content_num_forms</th>\n",
              "      <th>content_num_inputs</th>\n",
              "      <th>content_num_scripts</th>\n",
              "      <th>content_suspicious_keywords</th>\n",
              "      <th>semantic_coherence_score</th>\n",
              "      <th>brand_consistency_score</th>\n",
              "      <th>domain_age_missing</th>\n",
              "      <th>email_domain_freq</th>\n",
              "      <th>geo_freq</th>\n",
              "      <th>tld_trust_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.112281</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.043321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.227725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.680386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007117</td>\n",
              "      <td>0.223193</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.014035</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.119134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.730242</td>\n",
              "      <td>0.647518</td>\n",
              "      <td>0.013054</td>\n",
              "      <td>0.882602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.29652</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.238596</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.057762</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.026690</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.122807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.839831</td>\n",
              "      <td>0.556276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.659431</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.47363</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001779</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.140351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.900948</td>\n",
              "      <td>0.837386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.925418</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001779</td>\n",
              "      <td>0.080723</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   email_subject_len  email_has_urgent_keyword  web_url_len  web_who_is  \\\n",
              "0           0.112281                       1.0     0.043321         0.0   \n",
              "1           0.014035                       1.0     0.119134         0.0   \n",
              "2           0.238596                       1.0     0.057762         0.0   \n",
              "3           0.122807                       0.0     0.111913         0.0   \n",
              "4           0.140351                       0.0     0.090253         0.0   \n",
              "\n",
              "   web_https  web_js_len  web_js_obf_len  domain_age  js_obfuscation_ratio  \\\n",
              "0        1.0    0.227725        0.000000    0.680386              0.000000   \n",
              "1        0.0    0.730242        0.647518    0.013054              0.882602   \n",
              "2        1.0    0.000000        0.000000    0.000000              0.000000   \n",
              "3        0.0    0.839831        0.556276    0.000000              0.659431   \n",
              "4        0.0    0.900948        0.837386    0.000000              0.925418   \n",
              "\n",
              "   url_has_ip  ...  content_num_forms  content_num_inputs  \\\n",
              "0         0.0  ...                0.0            0.142857   \n",
              "1         0.0  ...                0.0            0.428571   \n",
              "2         0.0  ...                0.0            0.000000   \n",
              "3         0.0  ...                0.0            0.571429   \n",
              "4         0.0  ...                0.0            0.428571   \n",
              "\n",
              "   content_num_scripts  content_suspicious_keywords  semantic_coherence_score  \\\n",
              "0             0.166667                         0.75                   0.00000   \n",
              "1             0.708333                         0.75                   0.29652   \n",
              "2             0.000000                         0.00                   0.00000   \n",
              "3             0.833333                         0.75                   0.47363   \n",
              "4             0.708333                         0.50                   0.00000   \n",
              "\n",
              "   brand_consistency_score  domain_age_missing  email_domain_freq  geo_freq  \\\n",
              "0                      1.0                 0.0           0.007117  0.223193   \n",
              "1                      1.0                 0.0           0.000000  1.000000   \n",
              "2                      1.0                 1.0           0.026690  1.000000   \n",
              "3                      1.0                 1.0           0.001779  1.000000   \n",
              "4                      1.0                 1.0           0.001779  0.080723   \n",
              "\n",
              "   tld_trust_score  \n",
              "0              1.0  \n",
              "1              1.0  \n",
              "2              1.0  \n",
              "3              1.0  \n",
              "4              1.0  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First 5 rows of scaled training data\n",
        "print(\"Scaled Training Data:\")\n",
        "display(X_train_scaled.head())\n",
        "\n",
        "# First 5 rows of scaled test data\n",
        "print(\"\\nScaled Test Data:\")\n",
        "display(X_test_scaled.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a9f02e78",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Top MI Features\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>mi_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>web_js_len</td>\n",
              "      <td>0.657304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>js_obfuscation_ratio</td>\n",
              "      <td>0.521160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>web_js_obf_len</td>\n",
              "      <td>0.519802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>content_num_scripts</td>\n",
              "      <td>0.494982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>content_entropy</td>\n",
              "      <td>0.472273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>domain_trust_score</td>\n",
              "      <td>0.369185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>email_domain_freq</td>\n",
              "      <td>0.324097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>web_https</td>\n",
              "      <td>0.276868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>content_suspicious_keywords</td>\n",
              "      <td>0.269552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>web_who_is</td>\n",
              "      <td>0.261283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>content_num_inputs</td>\n",
              "      <td>0.253806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>domain_age</td>\n",
              "      <td>0.148078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>email_subject_len</td>\n",
              "      <td>0.137524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>domain_age_missing</td>\n",
              "      <td>0.071296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>url_num_hyphens</td>\n",
              "      <td>0.055126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        feature  mi_score\n",
              "5                    web_js_len  0.657304\n",
              "8          js_obfuscation_ratio  0.521160\n",
              "6                web_js_obf_len  0.519802\n",
              "28          content_num_scripts  0.494982\n",
              "22              content_entropy  0.472273\n",
              "23           domain_trust_score  0.369185\n",
              "33            email_domain_freq  0.324097\n",
              "4                     web_https  0.276868\n",
              "29  content_suspicious_keywords  0.269552\n",
              "3                    web_who_is  0.261283\n",
              "27           content_num_inputs  0.253806\n",
              "7                    domain_age  0.148078\n",
              "0             email_subject_len  0.137524\n",
              "32           domain_age_missing  0.071296\n",
              "11              url_num_hyphens  0.055126"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FEATURE SELECTION ON TRAIN DATA\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Compute MI scores\n",
        "mi_scores = mutual_info_classif(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create MI ranking dataframe\n",
        "mi_df = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'mi_score': mi_scores\n",
        "}).sort_values(by='mi_score', ascending=False)\n",
        "\n",
        "print(\" Top MI Features\")\n",
        "mi_df.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ QUBO Selected Features:\n",
            "['email_subject_len', 'web_js_len', 'url_num_hyphens', 'url_suspicious_chars', 'domain_contains_numbers', 'content_entropy']\n",
            "Total selected: 6\n",
            "📐 Shapes after QUBO selection:\n",
            "(6257, 6) (1565, 6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
        "\n",
        "# ================= PARAMETERS =================\n",
        "alpha = 0.6            # redundancy penalty\n",
        "beta = 2.0             # cardinality constraint strength\n",
        "k = 6                  # REQUIRED number of features\n",
        "num_reads = 120\n",
        "anneal_steps = 1200\n",
        "# ==============================================\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 1. FEATURE → LABEL MI\n",
        "# =========================\n",
        "MI_feat_label = mutual_info_classif(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 2. FEATURE ↔ FEATURE MI\n",
        "# =========================\n",
        "n_features = X_train_scaled.shape[1]\n",
        "MI_feat_feat = np.zeros((n_features, n_features))\n",
        "\n",
        "for i in range(n_features):\n",
        "    for j in range(i + 1, n_features):\n",
        "        MI = mutual_info_regression(\n",
        "            X_train_scaled.iloc[:, [i]],\n",
        "            X_train_scaled.iloc[:, j]\n",
        "        )[0]\n",
        "        MI_feat_feat[i, j] = MI\n",
        "        MI_feat_feat[j, i] = MI\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 3. BUILD QUBO (WITH CARDINALITY)\n",
        "# =========================\n",
        "Q = {}\n",
        "\n",
        "# Linear terms\n",
        "for i in range(n_features):\n",
        "    Q[(i, i)] = (\n",
        "        -MI_feat_label[i]           # relevance\n",
        "        + beta * (1 - 2 * k)        # cardinality\n",
        "    )\n",
        "\n",
        "# Quadratic terms\n",
        "for i in range(n_features):\n",
        "    for j in range(i + 1, n_features):\n",
        "        Q[(i, j)] = (\n",
        "            alpha * MI_feat_feat[i, j]   # redundancy\n",
        "            + 2 * beta                   # cardinality coupling\n",
        "        )\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 4. PURE PYTHON SA SAMPLER\n",
        "# =========================\n",
        "class SimulatedAnnealingSampler:\n",
        "\n",
        "    def sample_qubo(self, Q, num_reads=100, steps=1500):\n",
        "        n = max(max(i, j) for i, j in Q.keys()) + 1\n",
        "        samples = []\n",
        "\n",
        "        for _ in range(num_reads):\n",
        "            x = np.random.randint(0, 2, size=n)\n",
        "            energy = self._energy(Q, x)\n",
        "\n",
        "            for step in range(steps):\n",
        "                T = max(0.01, 1.0 - step / steps)\n",
        "                i = np.random.randint(n)\n",
        "\n",
        "                x[i] ^= 1\n",
        "                new_energy = self._energy(Q, x)\n",
        "                delta = new_energy - energy\n",
        "\n",
        "                if delta < 0 or np.random.rand() < np.exp(-delta / T):\n",
        "                    energy = new_energy\n",
        "                else:\n",
        "                    x[i] ^= 1\n",
        "\n",
        "            samples.append((dict(enumerate(x)), energy))\n",
        "\n",
        "        samples.sort(key=lambda s: s[1])\n",
        "        return SamplerResponse(samples)\n",
        "\n",
        "    def _energy(self, Q, x):\n",
        "        e = 0.0\n",
        "        for (i, j), q in Q.items():\n",
        "            e += q * x[i] * x[j]\n",
        "        return e\n",
        "\n",
        "\n",
        "class SamplerResponse:\n",
        "    def __init__(self, samples):\n",
        "        self.first = Sample(samples[0][0], samples[0][1])\n",
        "\n",
        "\n",
        "class Sample:\n",
        "    def __init__(self, sample, energy):\n",
        "        self.sample = sample\n",
        "        self.energy = energy\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 5. SOLVE QUBO\n",
        "# =========================\n",
        "sampler = SimulatedAnnealingSampler()\n",
        "response = sampler.sample_qubo(\n",
        "    Q,\n",
        "    num_reads=num_reads,\n",
        "    steps=anneal_steps\n",
        ")\n",
        "\n",
        "best_sample = response.first.sample\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 6. SELECT FEATURES\n",
        "# =========================\n",
        "selected_indices = [i for i, v in best_sample.items() if v == 1]\n",
        "selected_features = X_train_scaled.columns[selected_indices].tolist()\n",
        "\n",
        "print(\"✅ QUBO Selected Features:\")\n",
        "print(selected_features)\n",
        "print(f\"Total selected: {len(selected_features)}\")\n",
        "\n",
        "if len(selected_features) != k:\n",
        "    print(\"⚠ Cardinality slightly off — increase beta if needed\")\n",
        "\n",
        "X_train_selected = X_train_scaled[selected_features]\n",
        "X_test_selected = X_test_scaled[selected_features]\n",
        "\n",
        "print(\"📐 Shapes after QUBO selection:\")\n",
        "print(X_train_selected.shape, X_test_selected.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4a61e0ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " All libraries imported successfully!\n",
            " Using FidelityQuantumKernel (current API)\n"
          ]
        }
      ],
      "source": [
        "#CORRECTED IMPORTS\n",
        "\n",
        "# Qiskit imports (CORRECTED for 2025)\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
        "from qiskit_machine_learning.algorithms import QSVC\n",
        "from qiskit.primitives import Sampler\n",
        "from qiskit_aer import AerSimulator\n",
        "\n",
        "print(\" All libraries imported successfully!\")\n",
        "print(\" Using FidelityQuantumKernel (current API)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a258f0d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚛️ QSVM will use 6 qubits\n",
            "✅ Quantum kernel created\n",
            "• Circuit depth: 1\n",
            "\n",
            "🔬 Quantum Feature Map Circuit:\n",
            "     ┌───┐┌─────────────┐                                               »\n",
            "q_0: ┤ H ├┤ P(2.0*x[0]) ├──■────────────────────────────────────■───────»\n",
            "     ├───┤├─────────────┤┌─┴─┐┌──────────────────────────────┐┌─┴─┐     »\n",
            "q_1: ┤ H ├┤ P(2.0*x[1]) ├┤ X ├┤ P(2.0*(π - x[0])*(π - x[1])) ├┤ X ├──■──»\n",
            "     ├───┤├─────────────┤└───┘└──────────────────────────────┘└───┘┌─┴─┐»\n",
            "q_2: ┤ H ├┤ P(2.0*x[2]) ├──────────────────────────────────────────┤ X ├»\n",
            "     ├───┤├─────────────┤                                          └───┘»\n",
            "q_3: ┤ H ├┤ P(2.0*x[3]) ├───────────────────────────────────────────────»\n",
            "     ├───┤├─────────────┤                                               »\n",
            "q_4: ┤ H ├┤ P(2.0*x[4]) ├───────────────────────────────────────────────»\n",
            "     ├───┤├─────────────┤                                               »\n",
            "q_5: ┤ H ├┤ P(2.0*x[5]) ├───────────────────────────────────────────────»\n",
            "     └───┘└─────────────┘                                               »\n",
            "«                                               »\n",
            "«q_0: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_1: ──────────────────────────────────■───────»\n",
            "«     ┌──────────────────────────────┐┌─┴─┐     »\n",
            "«q_2: ┤ P(2.0*(π - x[1])*(π - x[2])) ├┤ X ├──■──»\n",
            "«     └──────────────────────────────┘└───┘┌─┴─┐»\n",
            "«q_3: ─────────────────────────────────────┤ X ├»\n",
            "«                                          └───┘»\n",
            "«q_4: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_5: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«                                               »\n",
            "«q_0: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_1: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_2: ──────────────────────────────────■───────»\n",
            "«     ┌──────────────────────────────┐┌─┴─┐     »\n",
            "«q_3: ┤ P(2.0*(π - x[2])*(π - x[3])) ├┤ X ├──■──»\n",
            "«     └──────────────────────────────┘└───┘┌─┴─┐»\n",
            "«q_4: ─────────────────────────────────────┤ X ├»\n",
            "«                                          └───┘»\n",
            "«q_5: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«                                               »\n",
            "«q_0: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_1: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_2: ──────────────────────────────────────────»\n",
            "«                                               »\n",
            "«q_3: ──────────────────────────────────■───────»\n",
            "«     ┌──────────────────────────────┐┌─┴─┐     »\n",
            "«q_4: ┤ P(2.0*(π - x[3])*(π - x[4])) ├┤ X ├──■──»\n",
            "«     └──────────────────────────────┘└───┘┌─┴─┐»\n",
            "«q_5: ─────────────────────────────────────┤ X ├»\n",
            "«                                          └───┘»\n",
            "«                                          \n",
            "«q_0: ─────────────────────────────────────\n",
            "«                                          \n",
            "«q_1: ─────────────────────────────────────\n",
            "«                                          \n",
            "«q_2: ─────────────────────────────────────\n",
            "«                                          \n",
            "«q_3: ─────────────────────────────────────\n",
            "«                                          \n",
            "«q_4: ──────────────────────────────────■──\n",
            "«     ┌──────────────────────────────┐┌─┴─┐\n",
            "«q_5: ┤ P(2.0*(π - x[4])*(π - x[5])) ├┤ X ├\n",
            "«     └──────────────────────────────┘└───┘\n",
            "✅ Data shuffled and π-scaled\n",
            "\n",
            "🚀 STARTING BATCH-WISE TRAINING\n",
            "\n",
            "📦 BATCH 1\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(251), np.int64(1): np.int64(249)}\n",
            "Balance ratio: 0.992\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.02s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 440.42s\n",
            "⏱️ QSVM is 26718.2× slower than SVM\n",
            "📦 BATCH 2\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(261), np.int64(1): np.int64(239)}\n",
            "Balance ratio: 0.916\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.29s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 557.86s\n",
            "⏱️ QSVM is 1897.0× slower than SVM\n",
            "📦 BATCH 3\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(251), np.int64(1): np.int64(249)}\n",
            "Balance ratio: 0.992\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.23s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 1094.39s\n",
            "⏱️ QSVM is 4662.6× slower than SVM\n",
            "📦 BATCH 4\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(260), np.int64(1): np.int64(240)}\n",
            "Balance ratio: 0.923\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.19s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 835.13s\n",
            "⏱️ QSVM is 4442.8× slower than SVM\n",
            "📦 BATCH 5\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(257), np.int64(1): np.int64(243)}\n",
            "Balance ratio: 0.946\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.17s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 738.06s\n",
            "⏱️ QSVM is 4333.2× slower than SVM\n",
            "📦 BATCH 6\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(243), np.int64(1): np.int64(257)}\n",
            "Balance ratio: 0.946\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.08s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 1040.28s\n",
            "⏱️ QSVM is 13473.6× slower than SVM\n",
            "📦 BATCH 7\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(265), np.int64(1): np.int64(235)}\n",
            "Balance ratio: 0.887\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.21s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 772.83s\n",
            "⏱️ QSVM is 3605.4× slower than SVM\n",
            "📦 BATCH 8\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(236), np.int64(1): np.int64(264)}\n",
            "Balance ratio: 0.894\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.10s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 1411.62s\n",
            "⏱️ QSVM is 14486.9× slower than SVM\n",
            "📦 BATCH 9\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(262), np.int64(1): np.int64(238)}\n",
            "Balance ratio: 0.908\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.20s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 1108.77s\n",
            "⏱️ QSVM is 5438.3× slower than SVM\n",
            "📦 BATCH 10\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(249), np.int64(1): np.int64(251)}\n",
            "Balance ratio: 0.992\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.19s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 819.00s\n",
            "⏱️ QSVM is 4408.3× slower than SVM\n",
            "📦 BATCH 11\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(255), np.int64(1): np.int64(245)}\n",
            "Balance ratio: 0.961\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.22s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 1248.26s\n",
            "⏱️ QSVM is 5697.4× slower than SVM\n",
            "📦 BATCH 12\n",
            "Samples: 500\n",
            "Class distribution: {np.int64(0): np.int64(263), np.int64(1): np.int64(237)}\n",
            "Balance ratio: 0.901\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.22s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 889.52s\n",
            "⏱️ QSVM is 4101.9× slower than SVM\n",
            "📦 BATCH 13\n",
            "Samples: 257\n",
            "Class distribution: {np.int64(0): np.int64(147), np.int64(1): np.int64(110)}\n",
            "Balance ratio: 0.748\n",
            "🔵 Training Classical SVM...\n",
            "✅ SVM trained in 0.19s\n",
            "⚛️ Training QSVM...\n",
            "  Predicted classes: [0 1]\n",
            "✅ QSVM trained in 252.21s\n",
            "⏱️ QSVM is 1311.3× slower than SVM\n",
            "\n",
            "======================================================================\n",
            "BATCH TRAINING COMPLETE\n",
            "======================================================================\n",
            "Total batches: 13\n",
            "Skipped batches: 0\n",
            "Successful batches: 13\n",
            "Success rate: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# FINAL CORRECTED CODE - BATCH-WISE SVM & QSVM TRAINING\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from qiskit.visualization import circuit_drawer\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "algorithm_globals.random_seed = 42\n",
        "\n",
        "n_qubo_features = len(selected_features)\n",
        "print(f\"⚛️ QSVM will use {n_qubo_features} qubits\")\n",
        "\n",
        "feature_map = ZZFeatureMap(\n",
        "    feature_dimension=n_qubo_features,\n",
        "    reps=1,\n",
        "    entanglement=\"linear\"\n",
        ")\n",
        "\n",
        "quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
        "\n",
        "print(\"✅ Quantum kernel created\")\n",
        "print(f\"• Circuit depth: {feature_map.depth()}\")\n",
        "\n",
        "if n_qubo_features <= 13:\n",
        "    print(\"\\n🔬 Quantum Feature Map Circuit:\")\n",
        "    print(feature_map.decompose().draw(output='text'))\n",
        "else:\n",
        "    print(\"\\n🔬 Quantum circuit too large to display\")\n",
        "\n",
        "BATCH_SIZE = 500        \n",
        "\n",
        "# Shuffle training data\n",
        "X_train_shuffled, y_train_shuffled = shuffle(\n",
        "    X_train_selected,\n",
        "    y_train,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Scale data to [0, π] for quantum models\n",
        "X_train_scaled_q = X_train_shuffled.values * np.pi\n",
        "X_test_scaled_q = X_test_selected.values * np.pi\n",
        "\n",
        "print(\"✅ Data shuffled and π-scaled\")\n",
        "\n",
        "svm_preds_list = []\n",
        "qsvm_preds_list = []\n",
        "\n",
        "total_batches = 0\n",
        "skipped_batches = 0\n",
        "\n",
        "print(\"\\n🚀 STARTING BATCH-WISE TRAINING\\n\")\n",
        "\n",
        "for i in range(0, len(X_train_shuffled), BATCH_SIZE):\n",
        "    batch_num = i // BATCH_SIZE + 1\n",
        "    total_batches += 1\n",
        "\n",
        "    X_batch = X_train_scaled_q[i:i+BATCH_SIZE]\n",
        "    y_batch = y_train_shuffled.iloc[i:i+BATCH_SIZE].values\n",
        "\n",
        "    unique_classes, class_counts = np.unique(y_batch, return_counts=True)\n",
        "    class_dist = dict(zip(unique_classes, class_counts))\n",
        "\n",
        "    print(f\"📦 BATCH {batch_num}\")\n",
        "    print(f\"Samples: {len(X_batch)}\")\n",
        "    print(f\"Class distribution: {class_dist}\")\n",
        "\n",
        "    if len(unique_classes) < 2:\n",
        "        print(\"⏭️ Skipped (single class batch)\")\n",
        "        skipped_batches += 1\n",
        "        continue\n",
        "\n",
        "    # Calculate class balance ratio\n",
        "    balance_ratio = min(class_counts) / max(class_counts)\n",
        "    print(f\"Balance ratio: {balance_ratio:.3f}\")\n",
        "\n",
        "    # -------- Classical SVM --------\n",
        "    print(\"🔵 Training Classical SVM...\")\n",
        "    svm_start = time.time()\n",
        "\n",
        "    svm = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "    svm.fit(X_batch, y_batch)\n",
        "\n",
        "    svm_time = time.time() - svm_start\n",
        "    svm_decision = svm.decision_function(X_test_scaled_q)\n",
        "    svm_pred = np.where(svm_decision >= 0, 1, 0)\n",
        "\n",
        "    print(f\"✅ SVM trained in {svm_time:.2f}s\")\n",
        "\n",
        "    # -------- QSVM --------\n",
        "    print(\"⚛️ Training QSVM...\")\n",
        "    qsvm_start = time.time()\n",
        "\n",
        "    qsvm = QSVC(\n",
        "        quantum_kernel=quantum_kernel,\n",
        "        C=1.0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        qsvm.fit(X_batch, y_batch)\n",
        "        qsvm_time = time.time() - qsvm_start\n",
        "\n",
        "        # Use decision_function instead of predict for stability\n",
        "        decision_scores = qsvm.decision_function(X_test_scaled_q)\n",
        "        qsvm_pred = np.where(decision_scores >= 0, 1, 0)\n",
        "    \n",
        "        # Verify we got both classes\n",
        "        unique_preds = np.unique(qsvm_pred)\n",
        "        print(f\"  Predicted classes: {unique_preds}\")\n",
        "\n",
        "        # SUCCESS - Add both predictions\n",
        "        qsvm_preds_list.append(qsvm_pred)\n",
        "        svm_preds_list.append(svm_pred)\n",
        "\n",
        "        print(f\"✅ QSVM trained in {qsvm_time:.2f}s\")\n",
        "        print(f\"⏱️ QSVM is {qsvm_time / svm_time:.1f}× slower than SVM\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ QSVM failed: {e}\")\n",
        "        print(\"   → Skipping this batch for both models\")\n",
        "        skipped_batches += 1\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"BATCH TRAINING COMPLETE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Total batches: {total_batches}\")\n",
        "print(f\"Skipped batches: {skipped_batches}\")\n",
        "print(f\"Successful batches: {len(svm_preds_list)}\")\n",
        "print(f\"Success rate: {len(svm_preds_list)/total_batches*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "11e388ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PROFESSIONAL QUANTUM CIRCUIT DIAGRAM\n",
            "======================================================================\n",
            "\n",
            "⚛️ Circuit Properties:\n",
            "   Qubits: 6\n",
            "   Depth: 17\n",
            "   Gates: 27\n",
            "\n",
            "✅ Professional circuit diagram saved: visualization_outputs/quantum_circuit_professional.html\n",
            "   Layout: Qiskit-style with proper gate boxes\n",
            "   Size: 6 qubits × 17 time steps\n",
            "   Gates: H (red), P/RZ (teal), CNOT (⊕)\n",
            "\n",
            "💡 How to view:\n",
            "   • Open in browser - will fit to window width\n",
            "   • Use mouse wheel to ZOOM in/out\n",
            "   • Click and DRAG to pan left/right\n",
            "   • Click camera icon to download high-res PNG\n",
            "✅ Gate legend saved: visualization_outputs/quantum_circuit_legend.html\n",
            "\n",
            "======================================================================\n",
            "✅ PROFESSIONAL CIRCUIT VISUALIZATION COMPLETE\n",
            "======================================================================\n",
            "\n",
            "Open visualization_outputs/quantum_circuit_professional.html in your browser to view!\n"
          ]
        }
      ],
      "source": [
        "# PROFESSIONAL QUANTUM CIRCUIT VISUALIZATION - QISKIT STYLE\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PROFESSIONAL QUANTUM CIRCUIT DIAGRAM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create output directory\n",
        "import os\n",
        "output_dir = \"visualization_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get circuit information\n",
        "circuit = feature_map.decompose()\n",
        "n_qubits = circuit.num_qubits\n",
        "\n",
        "print(f\"\\n⚛️ Circuit Properties:\")\n",
        "print(f\"   Qubits: {n_qubits}\")\n",
        "print(f\"   Depth: {circuit.depth()}\")\n",
        "print(f\"   Gates: {len(circuit.data)}\")\n",
        "\n",
        "# ============================================================\n",
        "# PARSE CIRCUIT AND ORGANIZE GATES BY TIME STEPS\n",
        "# ============================================================\n",
        "\n",
        "# Organize gates into time steps (columns)\n",
        "time_steps = {}\n",
        "qubit_usage = [0] * n_qubits  # Track current time for each qubit\n",
        "\n",
        "for instruction in circuit.data:\n",
        "    gate = instruction[0]\n",
        "    qubits_raw = instruction[1]\n",
        "    \n",
        "    # Handle different Qiskit versions\n",
        "    qubits = []\n",
        "    for q in qubits_raw:\n",
        "        if hasattr(q, 'index'):\n",
        "            qubits.append(q.index)\n",
        "        elif hasattr(q, '_index'):\n",
        "            qubits.append(q._index)\n",
        "        else:\n",
        "            # For newer versions, qubit might be directly indexable\n",
        "            qubits.append(circuit.qubits.index(q))\n",
        "    \n",
        "    # Find the earliest time this gate can be placed\n",
        "    max_time = max([qubit_usage[q] for q in qubits])\n",
        "    \n",
        "    # Place gate at this time\n",
        "    if max_time not in time_steps:\n",
        "        time_steps[max_time] = []\n",
        "    \n",
        "    time_steps[max_time].append({\n",
        "        'gate': gate.name,\n",
        "        'qubits': qubits,\n",
        "        'params': gate.params if hasattr(gate, 'params') else []\n",
        "    })\n",
        "    \n",
        "    # Update qubit usage\n",
        "    for q in qubits:\n",
        "        qubit_usage[q] = max_time + 1\n",
        "\n",
        "# ============================================================\n",
        "# CREATE PROFESSIONAL CIRCUIT DIAGRAM\n",
        "# ============================================================\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Layout parameters\n",
        "QUBIT_SPACING = 1.0\n",
        "GATE_SPACING = 1.5\n",
        "GATE_WIDTH = 0.6\n",
        "GATE_HEIGHT = 0.4\n",
        "\n",
        "max_time = max(time_steps.keys()) if time_steps else 0\n",
        "circuit_length = (max_time + 1) * GATE_SPACING + 1\n",
        "\n",
        "# Draw qubit lines (horizontal wires)\n",
        "for qubit_idx in range(n_qubits):\n",
        "    y = qubit_idx * QUBIT_SPACING\n",
        "    \n",
        "    # Main qubit line\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[0, circuit_length],\n",
        "        y=[y, y],\n",
        "        mode='lines',\n",
        "        line=dict(color='black', width=2),\n",
        "        showlegend=False,\n",
        "        hoverinfo='skip'\n",
        "    ))\n",
        "    \n",
        "    # Qubit label on the left\n",
        "    fig.add_annotation(\n",
        "        x=-0.3,\n",
        "        y=y,\n",
        "        text=f'q<sub>{qubit_idx}</sub> |0⟩',\n",
        "        showarrow=False,\n",
        "        xanchor='right',\n",
        "        font=dict(size=14, color='black')\n",
        "    )\n",
        "\n",
        "# Draw gates\n",
        "for time_idx, gates in time_steps.items():\n",
        "    x_pos = time_idx * GATE_SPACING + 1\n",
        "    \n",
        "    for gate_info in gates:\n",
        "        gate_name = gate_info['gate']\n",
        "        qubits = gate_info['qubits']\n",
        "        params = gate_info['params']\n",
        "        \n",
        "        if len(qubits) == 1:\n",
        "            # Single-qubit gate\n",
        "            qubit = qubits[0]\n",
        "            y_pos = qubit * QUBIT_SPACING\n",
        "            \n",
        "            # Determine gate color and label\n",
        "            if gate_name.lower() == 'h':\n",
        "                color = '#FF6B6B'  # Red for Hadamard\n",
        "                label = 'H'\n",
        "            elif gate_name.lower() in ['rz', 'p']:\n",
        "                color = '#4ECDC4'  # Teal for phase gates\n",
        "                label = 'P' if gate_name.lower() == 'p' else 'RZ'\n",
        "            elif gate_name.lower() == 'rx':\n",
        "                color = '#FFE66D'  # Yellow for RX\n",
        "                label = 'RX'\n",
        "            elif gate_name.lower() == 'ry':\n",
        "                color = '#A8E6CF'  # Green for RY\n",
        "                label = 'RY'\n",
        "            else:\n",
        "                color = '#95A5A6'  # Gray for others\n",
        "                label = gate_name.upper()\n",
        "            \n",
        "            # Draw gate box\n",
        "            fig.add_shape(\n",
        "                type=\"rect\",\n",
        "                x0=x_pos - GATE_WIDTH/2,\n",
        "                y0=y_pos - GATE_HEIGHT/2,\n",
        "                x1=x_pos + GATE_WIDTH/2,\n",
        "                y1=y_pos + GATE_HEIGHT/2,\n",
        "                fillcolor=color,\n",
        "                line=dict(color='black', width=2),\n",
        "            )\n",
        "            \n",
        "            # Add gate label\n",
        "            param_text = \"\"\n",
        "            if len(params) > 0:\n",
        "                # Simplify parameter display\n",
        "                param_text = f\"<br><sub>({str(params[0])[:15]})</sub>\"\n",
        "            \n",
        "            fig.add_annotation(\n",
        "                x=x_pos,\n",
        "                y=y_pos,\n",
        "                text=f\"<b>{label}</b>{param_text}\",\n",
        "                showarrow=False,\n",
        "                font=dict(size=12, color='white'),\n",
        "                bgcolor=color,\n",
        "                borderpad=4\n",
        "            )\n",
        "            \n",
        "        elif len(qubits) == 2:\n",
        "            # Two-qubit gate (controlled gate)\n",
        "            control_qubit = qubits[0]\n",
        "            target_qubit = qubits[1]\n",
        "            \n",
        "            y_control = control_qubit * QUBIT_SPACING\n",
        "            y_target = target_qubit * QUBIT_SPACING\n",
        "            \n",
        "            # Draw vertical connecting line\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[x_pos, x_pos],\n",
        "                y=[y_control, y_target],\n",
        "                mode='lines',\n",
        "                line=dict(color='black', width=2),\n",
        "                showlegend=False,\n",
        "                hoverinfo='skip'\n",
        "            ))\n",
        "            \n",
        "            # Draw control dot (filled circle)\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[x_pos],\n",
        "                y=[y_control],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=15,\n",
        "                    color='black',\n",
        "                    symbol='circle',\n",
        "                    line=dict(color='black', width=2)\n",
        "                ),\n",
        "                showlegend=False,\n",
        "                hovertext=f'Control: q{control_qubit}',\n",
        "                hoverinfo='text'\n",
        "            ))\n",
        "            \n",
        "            # Draw target (depends on gate type)\n",
        "            if gate_name.lower() in ['cx', 'cnot']:\n",
        "                # CNOT: Draw ⊕ symbol (circle with cross)\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=[x_pos],\n",
        "                    y=[y_target],\n",
        "                    mode='markers',\n",
        "                    marker=dict(\n",
        "                        size=25,\n",
        "                        color='white',\n",
        "                        symbol='circle',\n",
        "                        line=dict(color='black', width=3)\n",
        "                    ),\n",
        "                    showlegend=False,\n",
        "                    hovertext=f'Target: q{target_qubit}',\n",
        "                    hoverinfo='text'\n",
        "                ))\n",
        "                \n",
        "                # Add cross inside circle\n",
        "                cross_size = 0.15\n",
        "                # Vertical line of cross\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=[x_pos, x_pos],\n",
        "                    y=[y_target - cross_size, y_target + cross_size],\n",
        "                    mode='lines',\n",
        "                    line=dict(color='black', width=2),\n",
        "                    showlegend=False,\n",
        "                    hoverinfo='skip'\n",
        "                ))\n",
        "                # Horizontal line of cross\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=[x_pos - cross_size, x_pos + cross_size],\n",
        "                    y=[y_target, y_target],\n",
        "                    mode='lines',\n",
        "                    line=dict(color='black', width=2),\n",
        "                    showlegend=False,\n",
        "                    hoverinfo='skip'\n",
        "                ))\n",
        "                \n",
        "            elif gate_name.lower() == 'cz':\n",
        "                # CZ: Draw control dot on target too\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=[x_pos],\n",
        "                    y=[y_target],\n",
        "                    mode='markers',\n",
        "                    marker=dict(\n",
        "                        size=15,\n",
        "                        color='black',\n",
        "                        symbol='circle',\n",
        "                        line=dict(color='black', width=2)\n",
        "                    ),\n",
        "                    showlegend=False,\n",
        "                    hovertext=f'Target: q{target_qubit}',\n",
        "                    hoverinfo='text'\n",
        "                ))\n",
        "            else:\n",
        "                # Other controlled gates: draw as box\n",
        "                fig.add_shape(\n",
        "                    type=\"rect\",\n",
        "                    x0=x_pos - GATE_WIDTH/2,\n",
        "                    y0=y_target - GATE_HEIGHT/2,\n",
        "                    x1=x_pos + GATE_WIDTH/2,\n",
        "                    y1=y_target + GATE_HEIGHT/2,\n",
        "                    fillcolor='#4ECDC4',\n",
        "                    line=dict(color='black', width=2),\n",
        "                )\n",
        "                \n",
        "                fig.add_annotation(\n",
        "                    x=x_pos,\n",
        "                    y=y_target,\n",
        "                    text=f\"<b>{gate_name.upper()}</b>\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=12, color='white')\n",
        "                )\n",
        "\n",
        "# Update layout\n",
        "total_width = circuit_length * 100\n",
        "total_height = n_qubits * 80\n",
        "\n",
        "# If circuit is too wide, adjust spacing\n",
        "if total_width > 2000:\n",
        "    # Scale down for very wide circuits\n",
        "    scale_factor = 2000 / total_width\n",
        "    GATE_SPACING_DISPLAY = GATE_SPACING * scale_factor\n",
        "    total_width = 2000\n",
        "else:\n",
        "    GATE_SPACING_DISPLAY = GATE_SPACING\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f'⚛️ Quantum Circuit Diagram - {n_qubits} Qubits',\n",
        "    xaxis=dict(\n",
        "        showgrid=False,\n",
        "        zeroline=False,\n",
        "        showticklabels=True,\n",
        "        range=[-1, circuit_length + 0.5],\n",
        "        title='Gate Position'\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=False,\n",
        "        zeroline=False,\n",
        "        showticklabels=False,\n",
        "        range=[-0.5, (n_qubits - 1) * QUBIT_SPACING + 0.5],\n",
        "        scaleanchor=\"x\",\n",
        "        scaleratio=1\n",
        "    ),\n",
        "    plot_bgcolor='white',\n",
        "    height=max(500, total_height),\n",
        "    width=1400,  # Fixed width for browser\n",
        "    showlegend=False,\n",
        "    margin=dict(l=100, r=50, t=80, b=50),\n",
        "    # Enable drag and zoom\n",
        "    dragmode='pan',\n",
        "    hovermode='closest'\n",
        ")\n",
        "\n",
        "# Add zoom/pan instructions\n",
        "fig.add_annotation(\n",
        "    text='💡 Use mouse wheel to zoom, click and drag to pan',\n",
        "    xref='paper',\n",
        "    yref='paper',\n",
        "    x=0.5,\n",
        "    y=-0.05,\n",
        "    showarrow=False,\n",
        "    font=dict(size=10, color='gray'),\n",
        "    xanchor='center'\n",
        ")\n",
        "\n",
        "# Configure modebar (toolbar)\n",
        "config = {\n",
        "    'scrollZoom': True,\n",
        "    'displayModeBar': True,\n",
        "    'displaylogo': False,\n",
        "    'modeBarButtonsToAdd': ['pan2d', 'zoomIn2d', 'zoomOut2d', 'resetScale2d'],\n",
        "    'toImageButtonOptions': {\n",
        "        'format': 'png',\n",
        "        'filename': 'quantum_circuit',\n",
        "        'height': total_height,\n",
        "        'width': max(2000, int(circuit_length * 100)),\n",
        "        'scale': 2\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save with config\n",
        "filename = f\"{output_dir}/quantum_circuit_professional.html\"\n",
        "fig.write_html(filename, config=config)\n",
        "\n",
        "print(f\"\\n✅ Professional circuit diagram saved: {filename}\")\n",
        "print(f\"   Layout: Qiskit-style with proper gate boxes\")\n",
        "print(f\"   Size: {n_qubits} qubits × {max_time + 1} time steps\")\n",
        "print(f\"   Gates: H (red), P/RZ (teal), CNOT (⊕)\")\n",
        "print(f\"\\n💡 How to view:\")\n",
        "print(f\"   • Open in browser - will fit to window width\")\n",
        "print(f\"   • Use mouse wheel to ZOOM in/out\")\n",
        "print(f\"   • Click and DRAG to pan left/right\")\n",
        "print(f\"   • Click camera icon to download high-res PNG\")\n",
        "\n",
        "# ============================================================\n",
        "# CREATE LEGEND\n",
        "# ============================================================\n",
        "\n",
        "fig_legend = go.Figure()\n",
        "\n",
        "gate_types = [\n",
        "    ('H', '#FF6B6B', 'Hadamard Gate'),\n",
        "    ('P/RZ', '#4ECDC4', 'Phase/Rotation Gate'),\n",
        "    ('RX', '#FFE66D', 'X-Rotation Gate'),\n",
        "    ('RY', '#A8E6CF', 'Y-Rotation Gate'),\n",
        "    ('•─⊕', 'black', 'CNOT (Controlled-X)'),\n",
        "    ('•─•', 'black', 'CZ (Controlled-Z)')\n",
        "]\n",
        "\n",
        "for i, (label, color, desc) in enumerate(gate_types):\n",
        "    fig_legend.add_trace(go.Scatter(\n",
        "        x=[0.5],\n",
        "        y=[i],\n",
        "        mode='markers+text',\n",
        "        marker=dict(size=40, color=color, symbol='square', line=dict(color='black', width=2)),\n",
        "        text=label,\n",
        "        textposition='middle center',\n",
        "        textfont=dict(size=14, color='white' if color != '#FFE66D' else 'black'),\n",
        "        name=desc,\n",
        "        showlegend=True\n",
        "    ))\n",
        "\n",
        "fig_legend.update_layout(\n",
        "    title='⚛️ Quantum Gate Legend',\n",
        "    xaxis=dict(visible=False),\n",
        "    yaxis=dict(visible=False),\n",
        "    height=400,\n",
        "    width=600,\n",
        "    showlegend=True,\n",
        "    legend=dict(\n",
        "        orientation=\"v\",\n",
        "        yanchor=\"middle\",\n",
        "        y=0.5,\n",
        "        xanchor=\"left\",\n",
        "        x=0.7,\n",
        "        font=dict(size=14)\n",
        "    ),\n",
        "    plot_bgcolor='white'\n",
        ")\n",
        "\n",
        "filename_legend = f\"{output_dir}/quantum_circuit_legend.html\"\n",
        "fig_legend.write_html(filename_legend)\n",
        "print(f\"✅ Gate legend saved: {filename_legend}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ PROFESSIONAL CIRCUIT VISUALIZATION COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nOpen {filename} in your browser to view!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cdb5206a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "GENERATING ENSEMBLE PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "Total batches processed: 13\n",
            "Skipped batches: 0\n",
            "Successful batches: 13\n",
            "\n",
            "======================================================================\n",
            "CALCULATING BATCH WEIGHTS\n",
            "======================================================================\n",
            "\n",
            "📊 SVM Batch Weights (Accuracies):\n",
            "   Values: [0.9687 0.9725 0.9732 0.9719 0.9719 0.9719 0.9712 0.9738 0.9719 0.9725\n",
            " 0.9706 0.9712 0.9738]\n",
            "   Mean: 0.9719\n",
            "   Std:  0.0013\n",
            "   Range: [0.9687, 0.9738]\n",
            "\n",
            "📊 QSVM Batch Weights (Accuracies):\n",
            "   Values: [0.9617 0.9681 0.9681 0.9642 0.9668 0.9693 0.9642 0.9687 0.9655 0.9712\n",
            " 0.9636 0.9642 0.9617]\n",
            "   Mean: 0.9659\n",
            "   Std:  0.0029\n",
            "   Range: [0.9617, 0.9712]\n",
            "\n",
            "📋 Ensemble Shape: (1565, 13)\n",
            "   (n_samples=1565, n_models=13)\n",
            "\n",
            "======================================================================\n",
            "METHOD 1: MAJORITY VOTING\n",
            "======================================================================\n",
            "✅ Majority voting completed\n",
            "   Each of 13 models gets 1 vote\n",
            "   Prediction = class with most votes\n",
            "\n",
            "======================================================================\n",
            "METHOD 2: WEIGHTED VOTING\n",
            "======================================================================\n",
            "\n",
            "   📈 Voting Diagnostics:\n",
            "      Samples with model disagreement: 22/1565\n",
            "      Times weights changed outcome: 0\n",
            "      Weight influence rate: 0.00%\n",
            "\n",
            "   📈 Voting Diagnostics:\n",
            "      Samples with model disagreement: 127/1565\n",
            "      Times weights changed outcome: 0\n",
            "      Weight influence rate: 0.00%\n",
            "\n",
            "✅ Weighted voting completed\n",
            "   Each model gets vote weight = its accuracy\n",
            "   Prediction = class with highest weighted sum\n",
            "\n",
            "======================================================================\n",
            "VOTING METHOD COMPARISON\n",
            "======================================================================\n",
            "\n",
            "🔍 Predictions that differ between methods:\n",
            "   SVM:  0/1565 samples (0.00%)\n",
            "   QSVM: 0/1565 samples (0.00%)\n",
            "\n",
            "   ℹ️  Note: Majority and weighted voting give identical results\n",
            "   This happens when batch weights are very similar (stable training)\n",
            "\n",
            "======================================================================\n",
            "RESULTS - MAJORITY VOTING\n",
            "======================================================================\n",
            "\n",
            "🔵 CLASSICAL SVM - MAJORITY VOTING\n",
            "----------------------------------------------------------------------\n",
            "Accuracy: 0.9732\n",
            "\n",
            "Confusion Matrix:\n",
            "[[800   0]\n",
            " [ 42 723]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       800\n",
            "           1       1.00      0.95      0.97       765\n",
            "\n",
            "    accuracy                           0.97      1565\n",
            "   macro avg       0.98      0.97      0.97      1565\n",
            "weighted avg       0.97      0.97      0.97      1565\n",
            "\n",
            "\n",
            "⚛️  QUANTUM SVM - MAJORITY VOTING\n",
            "----------------------------------------------------------------------\n",
            "Accuracy: 0.9712\n",
            "\n",
            "Confusion Matrix:\n",
            "[[783  17]\n",
            " [ 28 737]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       800\n",
            "           1       0.98      0.96      0.97       765\n",
            "\n",
            "    accuracy                           0.97      1565\n",
            "   macro avg       0.97      0.97      0.97      1565\n",
            "weighted avg       0.97      0.97      0.97      1565\n",
            "\n",
            "\n",
            "======================================================================\n",
            "RESULTS - WEIGHTED VOTING\n",
            "======================================================================\n",
            "\n",
            "🔵 CLASSICAL SVM - WEIGHTED VOTING\n",
            "----------------------------------------------------------------------\n",
            "Accuracy: 0.9732\n",
            "\n",
            "Confusion Matrix:\n",
            "[[800   0]\n",
            " [ 42 723]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       800\n",
            "           1       1.00      0.95      0.97       765\n",
            "\n",
            "    accuracy                           0.97      1565\n",
            "   macro avg       0.98      0.97      0.97      1565\n",
            "weighted avg       0.97      0.97      0.97      1565\n",
            "\n",
            "\n",
            "⚛️  QUANTUM SVM - WEIGHTED VOTING\n",
            "----------------------------------------------------------------------\n",
            "Accuracy: 0.9712\n",
            "\n",
            "Confusion Matrix:\n",
            "[[783  17]\n",
            " [ 28 737]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       800\n",
            "           1       0.98      0.96      0.97       765\n",
            "\n",
            "    accuracy                           0.97      1565\n",
            "   macro avg       0.97      0.97      0.97      1565\n",
            "weighted avg       0.97      0.97      0.97      1565\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - ALL METHODS\n",
            "======================================================================\n",
            "\n",
            " Model        Method Accuracy Precision Recall F1-Score\n",
            "  SVM Majority Vote   0.9732    0.9745 0.9732   0.9731\n",
            "  SVM Weighted Vote   0.9732    0.9745 0.9732   0.9731\n",
            " QSVM Majority Vote   0.9712    0.9713 0.9712   0.9712\n",
            " QSVM Weighted Vote   0.9712    0.9713 0.9712   0.9712\n",
            "\n",
            "======================================================================\n",
            "BATCH-WISE ACCURACY ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "📊 SVM Individual Batch Accuracies:\n",
            "   Batch 1: 0.9687\n",
            "   Batch 2: 0.9725\n",
            "   Batch 3: 0.9732\n",
            "   Batch 4: 0.9719\n",
            "   Batch 5: 0.9719\n",
            "   Batch 6: 0.9719\n",
            "   Batch 7: 0.9712\n",
            "   Batch 8: 0.9738\n",
            "   Batch 9: 0.9719\n",
            "   Batch 10: 0.9725\n",
            "   Batch 11: 0.9706\n",
            "   Batch 12: 0.9712\n",
            "   Batch 13: 0.9738\n",
            "\n",
            "📊 QSVM Individual Batch Accuracies:\n",
            "   Batch 1: 0.9617\n",
            "   Batch 2: 0.9681\n",
            "   Batch 3: 0.9681\n",
            "   Batch 4: 0.9642\n",
            "   Batch 5: 0.9668\n",
            "   Batch 6: 0.9693\n",
            "   Batch 7: 0.9642\n",
            "   Batch 8: 0.9687\n",
            "   Batch 9: 0.9655\n",
            "   Batch 10: 0.9712\n",
            "   Batch 11: 0.9636\n",
            "   Batch 12: 0.9642\n",
            "   Batch 13: 0.9617\n",
            "\n",
            "📈 Statistics:\n",
            "   SVM  - Mean: 0.9719, Std: 0.0013\n",
            "   QSVM - Mean: 0.9659, Std: 0.0029\n",
            "\n",
            "======================================================================\n",
            "FINAL PREDICTIONS FOR DOWNSTREAM ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "✅ Using WEIGHTED VOTING as final predictions\n",
            "   SVM Final Accuracy:  0.9732\n",
            "   QSVM Final Accuracy: 0.9712\n",
            "\n",
            "💾 Variables created:\n",
            "   - svm_majority_pred, qsvm_majority_pred (majority voting)\n",
            "   - svm_weighted_pred, qsvm_weighted_pred (weighted voting)\n",
            "   - svm_final_pred, qsvm_final_pred (final predictions)\n",
            "   - svm_preds_list, qsvm_preds_list (individual batch predictions)\n",
            "   - svm_weights, qsvm_weights (batch weights)\n",
            "\n",
            "======================================================================\n",
            "ENSEMBLE VOTING COMPLETE ✅\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ENSEMBLE VOTING - MAJORITY AND WEIGHTED VOTING\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING ENSEMBLE PREDICTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Verify we have predictions\n",
        "print(f\"\\nTotal batches processed: {total_batches}\")\n",
        "print(f\"Skipped batches: {skipped_batches}\")\n",
        "print(f\"Successful batches: {len(svm_preds_list)}\")\n",
        "\n",
        "if len(svm_preds_list) == 0:\n",
        "    print(\"\\n❌ ERROR: No successful batches! Cannot perform ensemble voting.\")\n",
        "else:\n",
        "    # ============================================================\n",
        "    # STEP 1: CALCULATE BATCH WEIGHTS (based on accuracy)\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CALCULATING BATCH WEIGHTS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    svm_weights = []\n",
        "    qsvm_weights = []\n",
        "    \n",
        "    for i in range(len(svm_preds_list)):\n",
        "        svm_acc = accuracy_score(y_test, svm_preds_list[i])\n",
        "        qsvm_acc = accuracy_score(y_test, qsvm_preds_list[i])\n",
        "        svm_weights.append(svm_acc)\n",
        "        qsvm_weights.append(qsvm_acc)\n",
        "    \n",
        "    svm_weights = np.array(svm_weights)\n",
        "    qsvm_weights = np.array(qsvm_weights)\n",
        "    \n",
        "    print(f\"\\n📊 SVM Batch Weights (Accuracies):\")\n",
        "    print(f\"   Values: {np.round(svm_weights, 4)}\")\n",
        "    print(f\"   Mean: {svm_weights.mean():.4f}\")\n",
        "    print(f\"   Std:  {svm_weights.std():.4f}\")\n",
        "    print(f\"   Range: [{svm_weights.min():.4f}, {svm_weights.max():.4f}]\")\n",
        "    \n",
        "    print(f\"\\n📊 QSVM Batch Weights (Accuracies):\")\n",
        "    print(f\"   Values: {np.round(qsvm_weights, 4)}\")\n",
        "    print(f\"   Mean: {qsvm_weights.mean():.4f}\")\n",
        "    print(f\"   Std:  {qsvm_weights.std():.4f}\")\n",
        "    print(f\"   Range: [{qsvm_weights.min():.4f}, {qsvm_weights.max():.4f}]\")\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 2: CONVERT TO ENSEMBLE FORMAT\n",
        "    # ============================================================\n",
        "    \n",
        "    # Convert from (n_models, n_samples) to (n_samples, n_models)\n",
        "    svm_ensemble = np.array(svm_preds_list).T\n",
        "    qsvm_ensemble = np.array(qsvm_preds_list).T\n",
        "    \n",
        "    print(f\"\\n📋 Ensemble Shape: {svm_ensemble.shape}\")\n",
        "    print(f\"   (n_samples={svm_ensemble.shape[0]}, n_models={svm_ensemble.shape[1]})\")\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 3: MAJORITY VOTING\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"METHOD 1: MAJORITY VOTING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Each model gets 1 vote, class with most votes wins\n",
        "    svm_majority_pred = stats.mode(svm_ensemble, axis=1, keepdims=False)[0]\n",
        "    qsvm_majority_pred = stats.mode(qsvm_ensemble, axis=1, keepdims=False)[0]\n",
        "    \n",
        "    print(\"✅ Majority voting completed\")\n",
        "    print(f\"   Each of {svm_ensemble.shape[1]} models gets 1 vote\")\n",
        "    print(f\"   Prediction = class with most votes\")\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 4: WEIGHTED VOTING\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"METHOD 2: WEIGHTED VOTING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    def weighted_vote(pred_matrix, weights, verbose=False):\n",
        "        \"\"\"\n",
        "        Weighted voting ensemble\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        pred_matrix : ndarray, shape (n_samples, n_models)\n",
        "            Predictions from each model\n",
        "        weights : ndarray, shape (n_models,)\n",
        "            Weight for each model (typically accuracy)\n",
        "            \n",
        "        Returns:\n",
        "        --------\n",
        "        final_pred : ndarray, shape (n_samples,)\n",
        "            Final predictions\n",
        "        \"\"\"\n",
        "        final_pred = []\n",
        "        disagreement_count = 0\n",
        "        weight_made_difference = 0\n",
        "        \n",
        "        for i in range(pred_matrix.shape[0]):\n",
        "            # Calculate weighted votes for each class\n",
        "            votes = {}\n",
        "            for j, pred in enumerate(pred_matrix[i]):\n",
        "                votes[pred] = votes.get(pred, 0) + weights[j]\n",
        "            \n",
        "            # Get majority vote (for comparison)\n",
        "            unique, counts = np.unique(pred_matrix[i], return_counts=True)\n",
        "            majority = unique[np.argmax(counts)]\n",
        "            \n",
        "            # Get weighted vote\n",
        "            weighted = max(votes, key=votes.get)\n",
        "            \n",
        "            final_pred.append(weighted)\n",
        "            \n",
        "            # Track when models disagree\n",
        "            if len(unique) > 1:\n",
        "                disagreement_count += 1\n",
        "                if majority != weighted:\n",
        "                    weight_made_difference += 1\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"\\n   📈 Voting Diagnostics:\")\n",
        "            print(f\"      Samples with model disagreement: {disagreement_count}/{len(pred_matrix)}\")\n",
        "            if disagreement_count > 0:\n",
        "                print(f\"      Times weights changed outcome: {weight_made_difference}\")\n",
        "                print(f\"      Weight influence rate: {weight_made_difference/disagreement_count*100:.2f}%\")\n",
        "            else:\n",
        "                print(f\"      All models agreed on all samples\")\n",
        "        \n",
        "        return np.array(final_pred)\n",
        "    \n",
        "    # Apply weighted voting\n",
        "    svm_weighted_pred = weighted_vote(svm_ensemble, svm_weights, verbose=True)\n",
        "    qsvm_weighted_pred = weighted_vote(qsvm_ensemble, qsvm_weights, verbose=True)\n",
        "    \n",
        "    print(\"\\n✅ Weighted voting completed\")\n",
        "    print(f\"   Each model gets vote weight = its accuracy\")\n",
        "    print(f\"   Prediction = class with highest weighted sum\")\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 5: COMPARE VOTING METHODS\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VOTING METHOD COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Check if predictions differ\n",
        "    svm_diff = (svm_majority_pred != svm_weighted_pred).sum()\n",
        "    qsvm_diff = (qsvm_majority_pred != qsvm_weighted_pred).sum()\n",
        "    \n",
        "    print(f\"\\n🔍 Predictions that differ between methods:\")\n",
        "    print(f\"   SVM:  {svm_diff}/{len(svm_majority_pred)} samples ({svm_diff/len(svm_majority_pred)*100:.2f}%)\")\n",
        "    print(f\"   QSVM: {qsvm_diff}/{len(qsvm_majority_pred)} samples ({qsvm_diff/len(qsvm_majority_pred)*100:.2f}%)\")\n",
        "    \n",
        "    if svm_diff == 0 and qsvm_diff == 0:\n",
        "        print(\"\\n   ℹ️  Note: Majority and weighted voting give identical results\")\n",
        "        print(\"   This happens when batch weights are very similar (stable training)\")\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 6: DETAILED RESULTS - MAJORITY VOTING\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESULTS - MAJORITY VOTING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(\"\\n🔵 CLASSICAL SVM - MAJORITY VOTING\")\n",
        "    print(\"-\" * 70)\n",
        "    svm_maj_acc = accuracy_score(y_test, svm_majority_pred)\n",
        "    print(f\"Accuracy: {svm_maj_acc:.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, svm_majority_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, svm_majority_pred))\n",
        "    \n",
        "    print(\"\\n⚛️  QUANTUM SVM - MAJORITY VOTING\")\n",
        "    print(\"-\" * 70)\n",
        "    qsvm_maj_acc = accuracy_score(y_test, qsvm_majority_pred)\n",
        "    print(f\"Accuracy: {qsvm_maj_acc:.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, qsvm_majority_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, qsvm_majority_pred))\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 7: DETAILED RESULTS - WEIGHTED VOTING\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESULTS - WEIGHTED VOTING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(\"\\n🔵 CLASSICAL SVM - WEIGHTED VOTING\")\n",
        "    print(\"-\" * 70)\n",
        "    svm_wt_acc = accuracy_score(y_test, svm_weighted_pred)\n",
        "    print(f\"Accuracy: {svm_wt_acc:.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, svm_weighted_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, svm_weighted_pred))\n",
        "    \n",
        "    print(\"\\n⚛️  QUANTUM SVM - WEIGHTED VOTING\")\n",
        "    print(\"-\" * 70)\n",
        "    qsvm_wt_acc = accuracy_score(y_test, qsvm_weighted_pred)\n",
        "    print(f\"Accuracy: {qsvm_wt_acc:.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, qsvm_weighted_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, qsvm_weighted_pred))\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 8: SUMMARY TABLE\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SUMMARY - ALL METHODS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    summary_data = []\n",
        "    \n",
        "    # Get precision, recall, f1 for each method\n",
        "    svm_maj_prf = precision_recall_fscore_support(y_test, svm_majority_pred, average='weighted')[:3]\n",
        "    svm_wt_prf = precision_recall_fscore_support(y_test, svm_weighted_pred, average='weighted')[:3]\n",
        "    qsvm_maj_prf = precision_recall_fscore_support(y_test, qsvm_majority_pred, average='weighted')[:3]\n",
        "    qsvm_wt_prf = precision_recall_fscore_support(y_test, qsvm_weighted_pred, average='weighted')[:3]\n",
        "    \n",
        "    summary_data.append({\n",
        "        'Model': 'SVM',\n",
        "        'Method': 'Majority Vote',\n",
        "        'Accuracy': f\"{svm_maj_acc:.4f}\",\n",
        "        'Precision': f\"{svm_maj_prf[0]:.4f}\",\n",
        "        'Recall': f\"{svm_maj_prf[1]:.4f}\",\n",
        "        'F1-Score': f\"{svm_maj_prf[2]:.4f}\"\n",
        "    })\n",
        "    \n",
        "    summary_data.append({\n",
        "        'Model': 'SVM',\n",
        "        'Method': 'Weighted Vote',\n",
        "        'Accuracy': f\"{svm_wt_acc:.4f}\",\n",
        "        'Precision': f\"{svm_wt_prf[0]:.4f}\",\n",
        "        'Recall': f\"{svm_wt_prf[1]:.4f}\",\n",
        "        'F1-Score': f\"{svm_wt_prf[2]:.4f}\"\n",
        "    })\n",
        "    \n",
        "    summary_data.append({\n",
        "        'Model': 'QSVM',\n",
        "        'Method': 'Majority Vote',\n",
        "        'Accuracy': f\"{qsvm_maj_acc:.4f}\",\n",
        "        'Precision': f\"{qsvm_maj_prf[0]:.4f}\",\n",
        "        'Recall': f\"{qsvm_maj_prf[1]:.4f}\",\n",
        "        'F1-Score': f\"{qsvm_maj_prf[2]:.4f}\"\n",
        "    })\n",
        "    \n",
        "    summary_data.append({\n",
        "        'Model': 'QSVM',\n",
        "        'Method': 'Weighted Vote',\n",
        "        'Accuracy': f\"{qsvm_wt_acc:.4f}\",\n",
        "        'Precision': f\"{qsvm_wt_prf[0]:.4f}\",\n",
        "        'Recall': f\"{qsvm_wt_prf[1]:.4f}\",\n",
        "        'F1-Score': f\"{qsvm_wt_prf[2]:.4f}\"\n",
        "    })\n",
        "    \n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(\"\\n\", summary_df.to_string(index=False))\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 9: BATCH-WISE ACCURACY ANALYSIS\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BATCH-WISE ACCURACY ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    svm_batch_acc = [accuracy_score(y_test, preds) for preds in svm_preds_list]\n",
        "    qsvm_batch_acc = [accuracy_score(y_test, preds) for preds in qsvm_preds_list]\n",
        "    \n",
        "    print(f\"\\n📊 SVM Individual Batch Accuracies:\")\n",
        "    for i, acc in enumerate(svm_batch_acc, 1):\n",
        "        print(f\"   Batch {i}: {acc:.4f}\")\n",
        "    \n",
        "    print(f\"\\n📊 QSVM Individual Batch Accuracies:\")\n",
        "    for i, acc in enumerate(qsvm_batch_acc, 1):\n",
        "        print(f\"   Batch {i}: {acc:.4f}\")\n",
        "    \n",
        "    print(f\"\\n📈 Statistics:\")\n",
        "    print(f\"   SVM  - Mean: {np.mean(svm_batch_acc):.4f}, Std: {np.std(svm_batch_acc):.4f}\")\n",
        "    print(f\"   QSVM - Mean: {np.mean(qsvm_batch_acc):.4f}, Std: {np.std(qsvm_batch_acc):.4f}\")\n",
        "    \n",
        "    \n",
        "    # ============================================================\n",
        "    # STEP 10: CHOOSE FINAL PREDICTIONS\n",
        "    # ============================================================\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FINAL PREDICTIONS FOR DOWNSTREAM ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Use weighted voting as final (you can change this)\n",
        "    svm_final_pred = svm_weighted_pred\n",
        "    qsvm_final_pred = qsvm_weighted_pred\n",
        "    \n",
        "    print(\"\\n✅ Using WEIGHTED VOTING as final predictions\")\n",
        "    print(f\"   SVM Final Accuracy:  {accuracy_score(y_test, svm_final_pred):.4f}\")\n",
        "    print(f\"   QSVM Final Accuracy: {accuracy_score(y_test, qsvm_final_pred):.4f}\")\n",
        "    \n",
        "    print(\"\\n💾 Variables created:\")\n",
        "    print(\"   - svm_majority_pred, qsvm_majority_pred (majority voting)\")\n",
        "    print(\"   - svm_weighted_pred, qsvm_weighted_pred (weighted voting)\")\n",
        "    print(\"   - svm_final_pred, qsvm_final_pred (final predictions)\")\n",
        "    print(\"   - svm_preds_list, qsvm_preds_list (individual batch predictions)\")\n",
        "    print(\"   - svm_weights, qsvm_weights (batch weights)\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ENSEMBLE VOTING COMPLETE ✅\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "42de6629",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "COMPREHENSIVE VISUALIZATION & EXPLAINABILITY\n",
            "======================================================================\n",
            "\n",
            "💾 All plots will be saved as HTML files\n",
            "   You can open them in your web browser\n",
            "\n",
            "\n",
            "📊 SECTION 1: DATASET OVERVIEW\n",
            "----------------------------------------------------------------------\n",
            "✅ Class Distribution saved: visualization_outputs/01_class_distribution.html\n",
            "✅ Feature Statistics saved: visualization_outputs/02_feature_statistics.html\n",
            "\n",
            "🎯 SECTION 2: FEATURE SELECTION (QUBO)\n",
            "----------------------------------------------------------------------\n",
            "✅ Mutual Information saved: visualization_outputs/03_mutual_information.html\n",
            "✅ QUBO selection saved: visualization_outputs/04_qubo_selection.html\n",
            "\n",
            "🚀 SECTION 3: BATCH-WISE TRAINING ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "✅ Batch stability saved: visualization_outputs/05_batch_stability.html\n",
            "✅ Weight distribution saved: visualization_outputs/06_weight_distribution.html\n",
            "\n",
            "🎯 SECTION 4: MODEL PERFORMANCE COMPARISON\n",
            "----------------------------------------------------------------------\n",
            "✅ Confusion matrix saved: visualization_outputs/07_confusion_matrix.html\n",
            "✅ Performance metrics saved: visualization_outputs/08_performance_metrics.html\n",
            "✅ Per-class performance saved: visualization_outputs/09_per_class_performance.html\n",
            "\n",
            "🗳️ SECTION 5: VOTING METHOD COMPARISON\n",
            "----------------------------------------------------------------------\n",
            "✅ Voting comparison saved: visualization_outputs/10_voting_comparison.html\n",
            "\n",
            "🔍 SECTION 6: FEATURE CONTRIBUTION ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "✅ Feature contribution saved: visualization_outputs/11_feature_contribution.html\n",
            "\n",
            "   Features with largest difference:\n",
            "   • web_js_len: Legit=107.271, Phish=559.780, Diff=452.509\n",
            "   • email_subject_len: Legit=48.022, Phish=31.881, Diff=16.141\n",
            "   • url_num_hyphens: Legit=0.141, Phish=0.843, Diff=0.702\n",
            "   • content_entropy: Legit=4.721, Phish=4.371, Diff=0.350\n",
            "   • domain_contains_numbers: Legit=0.038, Phish=0.060, Diff=0.022\n",
            "\n",
            "🎨 SECTION 7: DECISION BOUNDARY VISUALIZATION\n",
            "----------------------------------------------------------------------\n",
            "✅ Decision boundary saved: visualization_outputs/12_decision_boundary.html\n",
            "\n",
            "======================================================================\n",
            "✅ ALL VISUALIZATIONS SAVED SUCCESSFULLY\n",
            "======================================================================\n",
            "\n",
            "📂 Output Directory: visualization_outputs/\n",
            "\n",
            "📊 Generated Files:\n",
            "   01_class_distribution.html\n",
            "   02_feature_statistics.html\n",
            "   03_mutual_information.html\n",
            "   04_qubo_selection.html\n",
            "   05_batch_stability.html\n",
            "   06_weight_distribution.html\n",
            "   07_confusion_matrix.html\n",
            "   08_performance_metrics.html\n",
            "   09_per_class_performance.html\n",
            "   10_voting_comparison.html\n",
            "   11_feature_contribution.html\n",
            "   12_decision_boundary.html\n",
            "\n",
            "🎯 Key Insights:\n",
            "   • Dataset: 7822 samples (4000 legitimate, 3822 phishing)\n",
            "   • Features: 6 selected by QUBO from 36 total\n",
            "   • SVM Accuracy: 0.9732\n",
            "   • QSVM Accuracy: 0.9712\n",
            "   • Batch Training: 13 successful batches\n",
            "   • Misclassifications: 45\n"
          ]
        }
      ],
      "source": [
        "# COMPREHENSIVE VISUALIZATION AND EXPLAINABILITY - FIXED VERSION\n",
        "# Saves all plots as HTML files for viewing in browser\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPREHENSIVE VISUALIZATION & EXPLAINABILITY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n💾 All plots will be saved as HTML files\")\n",
        "print(\"   You can open them in your web browser\\n\")\n",
        "\n",
        "# Create output directory for plots\n",
        "import os\n",
        "output_dir = \"visualization_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 1: DATASET OVERVIEW & EDA\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📊 SECTION 1: DATASET OVERVIEW\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 1.1 Class Distribution\n",
        "fig_class_dist = go.Figure()\n",
        "\n",
        "class_counts = df['final_label'].value_counts()\n",
        "total_count = len(df)\n",
        "\n",
        "fig_class_dist.add_trace(go.Bar(\n",
        "    x=['Legitimate (0)', 'Phishing (1)'],\n",
        "    y=[class_counts[0], class_counts[1]],\n",
        "    marker_color=['#2ecc71', '#e74c3c'],\n",
        "    text=[f'{class_counts[0]}<br>({class_counts[0]/total_count:.1%})', \n",
        "          f'{class_counts[1]}<br>({class_counts[1]/total_count:.1%})'],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{x}</b><br>Count: %{y}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_class_dist.update_layout(\n",
        "    title={\n",
        "        'text': '📧 Dataset Class Distribution',\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'font': {'size': 20, 'family': 'Arial Black'}\n",
        "    },\n",
        "    xaxis_title='Email Type',\n",
        "    yaxis_title='Count',\n",
        "    showlegend=False,\n",
        "    height=500,\n",
        "    template='plotly_white',\n",
        "    font=dict(size=12)\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/01_class_distribution.html\"\n",
        "fig_class_dist.write_html(filename)\n",
        "print(f\"✅ Class Distribution saved: {filename}\")\n",
        "\n",
        "\n",
        "# 1.2 Feature Statistics Heatmap\n",
        "numerical_features = X_train_selected.columns[:6]  # Top 6 features\n",
        "stats_data = []\n",
        "\n",
        "for feat in numerical_features:\n",
        "    stats_data.append({\n",
        "        'Feature': feat,\n",
        "        'Mean': X_train_selected[feat].mean(),\n",
        "        'Std': X_train_selected[feat].std(),\n",
        "        'Min': X_train_selected[feat].min(),\n",
        "        'Max': X_train_selected[feat].max()\n",
        "    })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_data)\n",
        "\n",
        "fig_stats = go.Figure(data=go.Heatmap(\n",
        "    z=stats_df[['Mean', 'Std', 'Min', 'Max']].values.T,\n",
        "    x=stats_df['Feature'],\n",
        "    y=['Mean', 'Std', 'Min', 'Max'],\n",
        "    colorscale='Viridis',\n",
        "    text=np.round(stats_df[['Mean', 'Std', 'Min', 'Max']].values.T, 3),\n",
        "    texttemplate='%{text}',\n",
        "    textfont={\"size\": 6},\n",
        "    hovertemplate='Feature: %{x}<br>Stat: %{y}<br>Value: %{z:.3f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_stats.update_layout(\n",
        "    title='📈 Feature Statistics Overview (Top 6 Features)',\n",
        "    xaxis_title='Features',\n",
        "    yaxis_title='Statistics',\n",
        "    height=400,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/02_feature_statistics.html\"\n",
        "fig_stats.write_html(filename)\n",
        "print(f\"✅ Feature Statistics saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 2: FEATURE SELECTION EXPLAINABILITY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🎯 SECTION 2: FEATURE SELECTION (QUBO)\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 2.1 Mutual Information Scores\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n",
        "mi_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'MI_Score': mi_scores\n",
        "}).sort_values('MI_Score', ascending=False)\n",
        "\n",
        "# Top 15 MI features\n",
        "fig_mi = go.Figure()\n",
        "\n",
        "fig_mi.add_trace(go.Bar(\n",
        "    x=mi_df.head(15)['MI_Score'],\n",
        "    y=mi_df.head(15)['Feature'],\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color=mi_df.head(15)['MI_Score'],\n",
        "        colorscale='Blues',\n",
        "        showscale=True,\n",
        "        colorbar=dict(title=\"MI Score\")\n",
        "    ),\n",
        "    text=np.round(mi_df.head(15)['MI_Score'], 3),\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>MI Score: %{x:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_mi.update_layout(\n",
        "    title='🎯 Top 15 Features by Mutual Information Score',\n",
        "    xaxis_title='Mutual Information Score',\n",
        "    yaxis_title='Features',\n",
        "    height=600,\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(autorange=\"reversed\")\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/03_mutual_information.html\"\n",
        "fig_mi.write_html(filename)\n",
        "print(f\"✅ Mutual Information saved: {filename}\")\n",
        "\n",
        "\n",
        "# 2.2 QUBO Selected Features Comparison\n",
        "fig_qubo = go.Figure()\n",
        "\n",
        "all_features = set(X_train.columns)\n",
        "selected = set(selected_features)\n",
        "not_selected = all_features - selected\n",
        "\n",
        "fig_qubo.add_trace(go.Bar(\n",
        "    name='Selected by QUBO',\n",
        "    x=['Selected', 'Not Selected'],\n",
        "    y=[len(selected), len(not_selected)],\n",
        "    marker_color=['#3498db', '#95a5a6'],\n",
        "    text=[len(selected), len(not_selected)],\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig_qubo.update_layout(\n",
        "    title=f'⚛️ QUBO Feature Selection: {len(selected)}/{len(all_features)} Features Selected',\n",
        "    yaxis_title='Number of Features',\n",
        "    height=400,\n",
        "    template='plotly_white',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/04_qubo_selection.html\"\n",
        "fig_qubo.write_html(filename)\n",
        "print(f\"✅ QUBO selection saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 3: TRAINING PROCESS VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🚀 SECTION 3: BATCH-WISE TRAINING ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 3.1 Batch Accuracy Stability\n",
        "svm_batch_acc = [accuracy_score(y_test, preds) for preds in svm_preds_list]\n",
        "qsvm_batch_acc = [accuracy_score(y_test, preds) for preds in qsvm_preds_list]\n",
        "\n",
        "fig_batch = go.Figure()\n",
        "\n",
        "# SVM line\n",
        "fig_batch.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(svm_batch_acc) + 1)),\n",
        "    y=svm_batch_acc,\n",
        "    mode='lines+markers',\n",
        "    name='Classical SVM',\n",
        "    line=dict(color='#3498db', width=3),\n",
        "    marker=dict(size=10, symbol='circle'),\n",
        "    hovertemplate='<b>SVM Batch %{x}</b><br>Accuracy: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "# QSVM line\n",
        "fig_batch.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(qsvm_batch_acc) + 1)),\n",
        "    y=qsvm_batch_acc,\n",
        "    mode='lines+markers',\n",
        "    name='Quantum SVM',\n",
        "    line=dict(color='#e74c3c', width=3),\n",
        "    marker=dict(size=10, symbol='diamond'),\n",
        "    hovertemplate='<b>QSVM Batch %{x}</b><br>Accuracy: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "# Add mean lines with better positioning\n",
        "svm_mean = np.mean(svm_batch_acc)\n",
        "qsvm_mean = np.mean(qsvm_batch_acc)\n",
        "\n",
        "fig_batch.add_hline(\n",
        "    y=svm_mean, \n",
        "    line_dash=\"dash\", \n",
        "    line_color=\"#3498db\",\n",
        "    line_width=2,\n",
        "    annotation_text=f\"SVM Mean: {svm_mean:.4f}\",\n",
        "    annotation_position=\"top right\",\n",
        "    annotation=dict(\n",
        "        font=dict(size=12, color=\"#3498db\"),\n",
        "        bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
        "        bordercolor=\"#3498db\",\n",
        "        borderwidth=1,\n",
        "        borderpad=4\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_batch.add_hline(\n",
        "    y=qsvm_mean, \n",
        "    line_dash=\"dash\", \n",
        "    line_color=\"#e74c3c\",\n",
        "    line_width=2,\n",
        "    annotation_text=f\"QSVM Mean: {qsvm_mean:.4f}\",\n",
        "    annotation_position=\"bottom right\",\n",
        "    annotation=dict(\n",
        "        font=dict(size=12, color=\"#e74c3c\"),\n",
        "        bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
        "        bordercolor=\"#e74c3c\",\n",
        "        borderwidth=1,\n",
        "        borderpad=4\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_batch.update_layout(\n",
        "    title='📊 Batch-wise Accuracy Stability',\n",
        "    xaxis_title='Batch Number',\n",
        "    yaxis_title='Accuracy',\n",
        "    height=500,\n",
        "    width=900,  # Added fixed width\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    margin=dict(r=150),  # Add right margin for annotations\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/05_batch_stability.html\"\n",
        "fig_batch.write_html(filename)\n",
        "print(f\"✅ Batch stability saved: {filename}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3.2 Batch Weight Distribution\n",
        "fig_weights = go.Figure()\n",
        "\n",
        "fig_weights.add_trace(go.Box(\n",
        "    y=svm_weights,\n",
        "    name='SVM Weights',\n",
        "    marker_color='#3498db',\n",
        "    boxmean='sd'\n",
        "))\n",
        "\n",
        "fig_weights.add_trace(go.Box(\n",
        "    y=qsvm_weights,\n",
        "    name='QSVM Weights',\n",
        "    marker_color='#e74c3c',\n",
        "    boxmean='sd'\n",
        "))\n",
        "\n",
        "fig_weights.update_layout(\n",
        "    title='📦 Batch Weight Distribution (Accuracy-based)',\n",
        "    yaxis_title='Weight (Accuracy)',\n",
        "    height=500,\n",
        "    template='plotly_white',\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/06_weight_distribution.html\"\n",
        "fig_weights.write_html(filename)\n",
        "print(f\"✅ Weight distribution saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 4: MODEL PERFORMANCE COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🎯 SECTION 4: MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 4.1 Confusion Matrix Comparison\n",
        "# Create subplot with 2 confusion matrices\n",
        "fig_cm = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('Classical SVM', 'Quantum SVM'),\n",
        "    specs=[[{\"type\": \"heatmap\"}, {\"type\": \"heatmap\"}]]\n",
        ")\n",
        "\n",
        "# SVM confusion matrix\n",
        "cm_svm = confusion_matrix(y_test, svm_final_pred)\n",
        "cm_svm_norm = cm_svm.astype('float') / cm_svm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "fig_cm.add_trace(\n",
        "    go.Heatmap(\n",
        "        z=cm_svm_norm,\n",
        "        x=['Predicted<br>Legitimate', 'Predicted<br>Phishing'],\n",
        "        y=['Actual<br>Legitimate', 'Actual<br>Phishing'],\n",
        "        text=cm_svm,\n",
        "        texttemplate='<b>%{text}</b><br>(%{z:.1%})',\n",
        "        colorscale='Blues',\n",
        "        showscale=False,\n",
        "        hovertemplate='Actual: %{y}<br>Predicted: %{x}<br>Count: %{text}<br>Rate: %{z:.2%}<extra></extra>'\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# QSVM confusion matrix\n",
        "cm_qsvm = confusion_matrix(y_test, qsvm_final_pred)\n",
        "cm_qsvm_norm = cm_qsvm.astype('float') / cm_qsvm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "fig_cm.add_trace(\n",
        "    go.Heatmap(\n",
        "        z=cm_qsvm_norm,\n",
        "        x=['Predicted<br>Legitimate', 'Predicted<br>Phishing'],\n",
        "        y=['Actual<br>Legitimate', 'Actual<br>Phishing'],\n",
        "        text=cm_qsvm,\n",
        "        texttemplate='<b>%{text}</b><br>(%{z:.1%})',\n",
        "        colorscale='Reds',\n",
        "        showscale=True,\n",
        "        colorbar=dict(title=\"Rate\", x=1.15),\n",
        "        hovertemplate='Actual: %{y}<br>Predicted: %{x}<br>Count: %{text}<br>Rate: %{z:.2%}<extra></extra>'\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig_cm.update_layout(\n",
        "    title_text='🎯 Confusion Matrix Comparison',\n",
        "    height=500,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/07_confusion_matrix.html\"\n",
        "fig_cm.write_html(filename)\n",
        "print(f\"✅ Confusion matrix saved: {filename}\")\n",
        "\n",
        "\n",
        "# 4.2 Performance Metrics Bar Chart\n",
        "svm_prf = precision_recall_fscore_support(y_test, svm_final_pred, average='weighted')\n",
        "qsvm_prf = precision_recall_fscore_support(y_test, qsvm_final_pred, average='weighted')\n",
        "\n",
        "svm_acc = accuracy_score(y_test, svm_final_pred)\n",
        "qsvm_acc = accuracy_score(y_test, qsvm_final_pred)\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "svm_scores = [svm_acc, svm_prf[0], svm_prf[1], svm_prf[2]]\n",
        "qsvm_scores = [qsvm_acc, qsvm_prf[0], qsvm_prf[1], qsvm_prf[2]]\n",
        "\n",
        "fig_metrics = go.Figure()\n",
        "\n",
        "fig_metrics.add_trace(go.Bar(\n",
        "    name='Classical SVM',\n",
        "    x=metrics,\n",
        "    y=svm_scores,\n",
        "    marker_color='#3498db',\n",
        "    text=[f'{v:.4f}' for v in svm_scores],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>SVM %{x}</b><br>Score: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_metrics.add_trace(go.Bar(\n",
        "    name='Quantum SVM',\n",
        "    x=metrics,\n",
        "    y=qsvm_scores,\n",
        "    marker_color='#e74c3c',\n",
        "    text=[f'{v:.4f}' for v in qsvm_scores],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>QSVM %{x}</b><br>Score: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_metrics.update_layout(\n",
        "    title='📊 Performance Metrics Comparison',\n",
        "    yaxis_title='Score',\n",
        "    yaxis=dict(range=[0.8, 1.0]),\n",
        "    barmode='group',\n",
        "    height=500,\n",
        "    template='plotly_white',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/08_performance_metrics.html\"\n",
        "fig_metrics.write_html(filename)\n",
        "print(f\"✅ Performance metrics saved: {filename}\")\n",
        "\n",
        "\n",
        "# 4.3 Per-Class Performance\n",
        "svm_pc = precision_recall_fscore_support(y_test, svm_final_pred, average=None)\n",
        "qsvm_pc = precision_recall_fscore_support(y_test, qsvm_final_pred, average=None)\n",
        "\n",
        "class_names = ['Legitimate', 'Phishing']\n",
        "\n",
        "fig_class_perf = make_subplots(\n",
        "    rows=1, cols=3,\n",
        "    subplot_titles=('Precision', 'Recall', 'F1-Score'),\n",
        "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        ")\n",
        "\n",
        "# Precision\n",
        "fig_class_perf.add_trace(\n",
        "    go.Bar(name='SVM', x=class_names, y=svm_pc[0], marker_color='#3498db',\n",
        "           text=[f'{v:.3f}' for v in svm_pc[0]], textposition='auto'),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig_class_perf.add_trace(\n",
        "    go.Bar(name='QSVM', x=class_names, y=qsvm_pc[0], marker_color='#e74c3c',\n",
        "           text=[f'{v:.3f}' for v in qsvm_pc[0]], textposition='auto'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Recall\n",
        "fig_class_perf.add_trace(\n",
        "    go.Bar(name='SVM', x=class_names, y=svm_pc[1], marker_color='#3498db',\n",
        "           text=[f'{v:.3f}' for v in svm_pc[1]], textposition='auto', showlegend=False),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig_class_perf.add_trace(\n",
        "    go.Bar(name='QSVM', x=class_names, y=qsvm_pc[1], marker_color='#e74c3c',\n",
        "           text=[f'{v:.3f}' for v in qsvm_pc[1]], textposition='auto', showlegend=False),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# F1-Score\n",
        "fig_class_perf.add_trace(\n",
        "    go.Bar(name='SVM', x=class_names, y=svm_pc[2], marker_color='#3498db',\n",
        "           text=[f'{v:.3f}' for v in svm_pc[2]], textposition='auto', showlegend=False),\n",
        "    row=1, col=3\n",
        ")\n",
        "fig_class_perf.add_trace(\n",
        "    go.Bar(name='QSVM', x=class_names, y=qsvm_pc[2], marker_color='#e74c3c',\n",
        "           text=[f'{v:.3f}' for v in qsvm_pc[2]], textposition='auto', showlegend=False),\n",
        "    row=1, col=3\n",
        ")\n",
        "\n",
        "fig_class_perf.update_layout(\n",
        "    title_text='📈 Per-Class Performance Comparison',\n",
        "    height=500,\n",
        "    template='plotly_white',\n",
        "    barmode='group',\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig_class_perf.update_yaxes(range=[0.8, 1.0])\n",
        "\n",
        "filename = f\"{output_dir}/09_per_class_performance.html\"\n",
        "fig_class_perf.write_html(filename)\n",
        "print(f\"✅ Per-class performance saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 5: VOTING METHOD COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🗳️ SECTION 5: VOTING METHOD COMPARISON\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Calculate accuracies for all methods\n",
        "svm_maj_acc = accuracy_score(y_test, svm_majority_pred)\n",
        "svm_wt_acc = accuracy_score(y_test, svm_weighted_pred)\n",
        "qsvm_maj_acc = accuracy_score(y_test, qsvm_majority_pred)\n",
        "qsvm_wt_acc = accuracy_score(y_test, qsvm_weighted_pred)\n",
        "\n",
        "fig_voting = go.Figure()\n",
        "\n",
        "methods = ['Majority<br>Voting', 'Weighted<br>Voting']\n",
        "\n",
        "fig_voting.add_trace(go.Bar(\n",
        "    name='Classical SVM',\n",
        "    x=methods,\n",
        "    y=[svm_maj_acc, svm_wt_acc],\n",
        "    marker_color='#3498db',\n",
        "    text=[f'{svm_maj_acc:.4f}', f'{svm_wt_acc:.4f}'],\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig_voting.add_trace(go.Bar(\n",
        "    name='Quantum SVM',\n",
        "    x=methods,\n",
        "    y=[qsvm_maj_acc, qsvm_wt_acc],\n",
        "    marker_color='#e74c3c',\n",
        "    text=[f'{qsvm_maj_acc:.4f}', f'{qsvm_wt_acc:.4f}'],\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig_voting.update_layout(\n",
        "    title='🗳️ Voting Method Comparison: Majority vs Weighted',\n",
        "    yaxis_title='Accuracy',\n",
        "    yaxis=dict(range=[0.85, 1.0]),\n",
        "    barmode='group',\n",
        "    height=500,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/10_voting_comparison.html\"\n",
        "fig_voting.write_html(filename)\n",
        "print(f\"✅ Voting comparison saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 6: FEATURE CONTRIBUTION ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🔍 SECTION 6: FEATURE CONTRIBUTION ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Compare feature values for legitimate vs phishing emails\n",
        "feature_contrib_data = []\n",
        "\n",
        "# Get indices for each class\n",
        "legit_indices = y_train[y_train == 0].index\n",
        "phish_indices = y_train[y_train == 1].index\n",
        "\n",
        "for feat in selected_features[:10]:  # Top 10 QUBO features\n",
        "    legit_mean = X_train.loc[legit_indices, feat].mean()\n",
        "    phish_mean = X_train.loc[phish_indices, feat].mean()\n",
        "    diff = abs(phish_mean - legit_mean)\n",
        "    \n",
        "    feature_contrib_data.append({\n",
        "        'Feature': feat,\n",
        "        'Legitimate_Mean': legit_mean,\n",
        "        'Phishing_Mean': phish_mean,\n",
        "        'Difference': diff\n",
        "    })\n",
        "\n",
        "contrib_df = pd.DataFrame(feature_contrib_data).sort_values('Difference', ascending=False)\n",
        "\n",
        "fig_contrib = go.Figure()\n",
        "\n",
        "fig_contrib.add_trace(go.Bar(\n",
        "    name='Legitimate Emails',\n",
        "    y=contrib_df['Feature'],\n",
        "    x=contrib_df['Legitimate_Mean'],\n",
        "    orientation='h',\n",
        "    marker_color='#2ecc71',\n",
        "    text=[f'{v:.3f}' for v in contrib_df['Legitimate_Mean']],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Legitimate: %{x:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_contrib.add_trace(go.Bar(\n",
        "    name='Phishing Emails',\n",
        "    y=contrib_df['Feature'],\n",
        "    x=contrib_df['Phishing_Mean'],\n",
        "    orientation='h',\n",
        "    marker_color='#e74c3c',\n",
        "    text=[f'{v:.3f}' for v in contrib_df['Phishing_Mean']],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Phishing: %{x:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_contrib.update_layout(\n",
        "    title='🔍 Feature Value Comparison: Legitimate vs Phishing',\n",
        "    xaxis_title='Mean Feature Value',\n",
        "    yaxis_title='Features',\n",
        "    barmode='group',\n",
        "    height=600,\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(autorange=\"reversed\"),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/11_feature_contribution.html\"\n",
        "fig_contrib.write_html(filename)\n",
        "print(f\"✅ Feature contribution saved: {filename}\")\n",
        "\n",
        "# Print insights\n",
        "print(f\"\\n   Features with largest difference:\")\n",
        "for i, row in contrib_df.head(5).iterrows():\n",
        "    print(f\"   • {row['Feature']}: Legit={row['Legitimate_Mean']:.3f}, Phish={row['Phishing_Mean']:.3f}, Diff={row['Difference']:.3f}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 7: DECISION BOUNDARY VISUALIZATION (2D PCA)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🎨 SECTION 7: DECISION BOUNDARY VISUALIZATION\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce to 2D for visualization\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_test_pca = pca.fit_transform(X_test_scaled[selected_features])\n",
        "\n",
        "# Create scatter plot\n",
        "fig_boundary = go.Figure()\n",
        "\n",
        "# Actual labels\n",
        "fig_boundary.add_trace(go.Scatter(\n",
        "    x=X_test_pca[y_test==0, 0],\n",
        "    y=X_test_pca[y_test==0, 1],\n",
        "    mode='markers',\n",
        "    name='Legitimate (Actual)',\n",
        "    marker=dict(size=8, color='#2ecc71', symbol='circle', opacity=0.6)\n",
        "))\n",
        "\n",
        "fig_boundary.add_trace(go.Scatter(\n",
        "    x=X_test_pca[y_test==1, 0],\n",
        "    y=X_test_pca[y_test==1, 1],\n",
        "    mode='markers',\n",
        "    name='Phishing (Actual)',\n",
        "    marker=dict(size=8, color='#e74c3c', symbol='x', opacity=0.6)\n",
        "))\n",
        "\n",
        "# Misclassifications\n",
        "misclass_idx = np.where(qsvm_final_pred != y_test)[0]\n",
        "if len(misclass_idx) > 0:\n",
        "    fig_boundary.add_trace(go.Scatter(\n",
        "        x=X_test_pca[misclass_idx, 0],\n",
        "        y=X_test_pca[misclass_idx, 1],\n",
        "        mode='markers',\n",
        "        name='Misclassified',\n",
        "        marker=dict(size=12, color='yellow', symbol='circle-open', \n",
        "                   line=dict(width=2, color='black'))\n",
        "    ))\n",
        "\n",
        "fig_boundary.update_layout(\n",
        "    title=f'🎨 Decision Space (PCA 2D) - {len(misclass_idx)} Misclassifications',\n",
        "    xaxis_title=f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)',\n",
        "    yaxis_title=f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)',\n",
        "    height=600,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/12_decision_boundary.html\"\n",
        "fig_boundary.write_html(filename)\n",
        "print(f\"✅ Decision boundary saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ ALL VISUALIZATIONS SAVED SUCCESSFULLY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📂 Output Directory: {output_dir}/\")\n",
        "print(\"\\n📊 Generated Files:\")\n",
        "print(\"   01_class_distribution.html\")\n",
        "print(\"   02_feature_statistics.html\")\n",
        "print(\"   03_mutual_information.html\")\n",
        "print(\"   04_qubo_selection.html\")\n",
        "print(\"   05_batch_stability.html\")\n",
        "print(\"   06_weight_distribution.html\")\n",
        "print(\"   07_confusion_matrix.html\")\n",
        "print(\"   08_performance_metrics.html\")\n",
        "print(\"   09_per_class_performance.html\")\n",
        "print(\"   10_voting_comparison.html\")\n",
        "print(\"   11_feature_contribution.html\")\n",
        "print(\"   12_decision_boundary.html\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n🎯 Key Insights:\")\n",
        "print(f\"   • Dataset: {len(df)} samples ({class_counts[0]} legitimate, {class_counts[1]} phishing)\")\n",
        "print(f\"   • Features: {len(selected_features)} selected by QUBO from {len(X_train.columns)} total\")\n",
        "print(f\"   • SVM Accuracy: {svm_acc:.4f}\")\n",
        "print(f\"   • QSVM Accuracy: {qsvm_acc:.4f}\")\n",
        "print(f\"   • Batch Training: {len(svm_preds_list)} successful batches\")\n",
        "print(f\"   • Misclassifications: {len(misclass_idx)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "16c7504a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FEATURE COMPARISON: LEGITIMATE VS PHISHING\n",
            "======================================================================\n",
            "\n",
            "Analyzing features...\n",
            "   Legitimate emails: 3200\n",
            "   Phishing emails: 3057\n",
            "\n",
            "📊 SECTION 1: ALL FEATURES COMPARISON\n",
            "----------------------------------------------------------------------\n",
            "✅ Analyzed 36 features\n",
            "\n",
            "   Top 5 features with largest differences:\n",
            "   8. domain_age: Legit=7778.861, Phish=3747.043, Diff=4031.818\n",
            "   6. web_js_len: Legit=107.271, Phish=559.780, Diff=452.509\n",
            "   7. web_js_obf_len: Legit=0.000, Phish=366.361, Diff=366.361\n",
            "   1. email_subject_len: Legit=48.022, Phish=31.881, Diff=16.141\n",
            "   29. content_num_scripts: Legit=2.176, Phish=11.274, Diff=9.098\n",
            "\n",
            "✅ Top 20 features chart saved: visualization_outputs/feature_comparison_top20.html\n",
            "\n",
            "📊 Creating charts for all 36 features in 2 batches...\n",
            "   ✅ Batch 1/2 saved: visualization_outputs/feature_comparison_all_batch01.html\n",
            "   ✅ Batch 2/2 saved: visualization_outputs/feature_comparison_all_batch02.html\n",
            "\n",
            "🎯 SECTION 2: MI-SELECTED FEATURES COMPARISON\n",
            "----------------------------------------------------------------------\n",
            "   Calculating Mutual Information scores...\n",
            "✅ Selected top 15 features by Mutual Information\n",
            "\n",
            "   Top 5 MI features:\n",
            "   6. web_js_len: MI=0.6573\n",
            "   9. js_obfuscation_ratio: MI=0.5212\n",
            "   7. web_js_obf_len: MI=0.5198\n",
            "   29. content_num_scripts: MI=0.4950\n",
            "   23. content_entropy: MI=0.4723\n",
            "\n",
            "✅ Top MI features chart saved: visualization_outputs/feature_comparison_top_MI.html\n",
            "\n",
            "⚛️ SECTION 3: QUBO-SELECTED FEATURES COMPARISON\n",
            "----------------------------------------------------------------------\n",
            "✅ Analyzed 6 QUBO-selected features\n",
            "\n",
            "✅ QUBO features chart saved: visualization_outputs/feature_comparison_QUBO_selected.html\n",
            "\n",
            "📊 SECTION 4: SUMMARY STATISTICS\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "          Category  Count  Avg Difference  Max Difference\n",
            "      All Features     36      135.691128     4031.818100\n",
            "Top 15 MI Features     15      325.533584     4031.818100\n",
            "     QUBO Selected      6       78.290546      452.509025\n",
            "\n",
            "✅ Summary saved: visualization_outputs/feature_comparison_summary.csv\n",
            "\n",
            "======================================================================\n",
            "✅ FEATURE COMPARISON COMPLETE\n",
            "======================================================================\n",
            "\n",
            "📂 Output Directory: visualization_outputs/\n",
            "\n",
            "📊 Generated Files:\n",
            "   • feature_comparison_top20.html (Top 20 features)\n",
            "   • feature_comparison_all_batch01.html to batch02.html (All features)\n",
            "   • feature_comparison_top_MI.html (Top 15 MI features)\n",
            "   • feature_comparison_QUBO_selected.html (QUBO features)\n",
            "   • feature_comparison_summary.csv (Summary statistics)\n",
            "\n",
            "🌐 To view: Open any .html file in your web browser\n",
            "\n",
            "🎯 Key Insights:\n",
            "   • Total features analyzed: 36\n",
            "   • Feature with largest difference: domain_age\n",
            "   • Difference: 4031.818\n",
            "   • Top MI feature: web_js_len (MI=0.6573)\n"
          ]
        }
      ],
      "source": [
        "# COMPREHENSIVE FEATURE COMPARISON - LEGITIMATE VS PHISHING\n",
        "# Generates comparison charts for all features and MI-selected features\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FEATURE COMPARISON: LEGITIMATE VS PHISHING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"visualization_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get class indices\n",
        "legit_indices = y_train[y_train == 0].index\n",
        "phish_indices = y_train[y_train == 1].index\n",
        "\n",
        "print(f\"\\nAnalyzing features...\")\n",
        "print(f\"   Legitimate emails: {len(legit_indices)}\")\n",
        "print(f\"   Phishing emails: {len(phish_indices)}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 1: ALL FEATURES COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📊 SECTION 1: ALL FEATURES COMPARISON\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "all_features = X_train.columns.tolist()\n",
        "feature_comparison_data = []\n",
        "\n",
        "for feat in all_features:\n",
        "    legit_mean = X_train.loc[legit_indices, feat].mean()\n",
        "    phish_mean = X_train.loc[phish_indices, feat].mean()\n",
        "    diff = abs(phish_mean - legit_mean)\n",
        "    \n",
        "    feature_comparison_data.append({\n",
        "        'Feature': feat,\n",
        "        'Legitimate_Mean': legit_mean,\n",
        "        'Phishing_Mean': phish_mean,\n",
        "        'Absolute_Difference': diff,\n",
        "        'Relative_Difference': diff / (legit_mean + 0.0001)  # Avoid division by zero\n",
        "    })\n",
        "\n",
        "all_features_df = pd.DataFrame(feature_comparison_data)\n",
        "all_features_df = all_features_df.sort_values('Absolute_Difference', ascending=False)\n",
        "\n",
        "print(f\"✅ Analyzed {len(all_features)} features\")\n",
        "print(f\"\\n   Top 5 features with largest differences:\")\n",
        "for i, row in all_features_df.head(5).iterrows():\n",
        "    print(f\"   {i+1}. {row['Feature']}: Legit={row['Legitimate_Mean']:.3f}, Phish={row['Phishing_Mean']:.3f}, Diff={row['Absolute_Difference']:.3f}\")\n",
        "\n",
        "\n",
        "# Create visualization for ALL features (top 20)\n",
        "fig_all = go.Figure()\n",
        "\n",
        "top_20_features = all_features_df.head(20)\n",
        "\n",
        "fig_all.add_trace(go.Bar(\n",
        "    name='Legitimate Emails',\n",
        "    y=top_20_features['Feature'],\n",
        "    x=top_20_features['Legitimate_Mean'],\n",
        "    orientation='h',\n",
        "    marker_color='#2ecc71',\n",
        "    text=[f'{v:.3f}' for v in top_20_features['Legitimate_Mean']],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Legitimate: %{x:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_all.add_trace(go.Bar(\n",
        "    name='Phishing Emails',\n",
        "    y=top_20_features['Feature'],\n",
        "    x=top_20_features['Phishing_Mean'],\n",
        "    orientation='h',\n",
        "    marker_color='#e74c3c',\n",
        "    text=[f'{v:.3f}' for v in top_20_features['Phishing_Mean']],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Phishing: %{x:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_all.update_layout(\n",
        "    title='🔍 Feature Value Comparison: Legitimate vs Phishing (Top 20 by Difference)',\n",
        "    xaxis_title='Mean Feature Value',\n",
        "    yaxis_title='Features',\n",
        "    barmode='group',\n",
        "    height=800,\n",
        "    width=1000,\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(autorange=\"reversed\"),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/feature_comparison_top20.html\"\n",
        "fig_all.write_html(filename)\n",
        "print(f\"\\n✅ Top 20 features chart saved: {filename}\")\n",
        "\n",
        "\n",
        "# Create comprehensive chart with ALL features (in batches of 25)\n",
        "num_features = len(all_features)\n",
        "batch_size = 25\n",
        "num_batches = (num_features + batch_size - 1) // batch_size\n",
        "\n",
        "print(f\"\\n📊 Creating charts for all {num_features} features in {num_batches} batches...\")\n",
        "\n",
        "for batch_idx in range(num_batches):\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min(start_idx + batch_size, num_features)\n",
        "    batch_features = all_features_df.iloc[start_idx:end_idx]\n",
        "    \n",
        "    fig_batch = go.Figure()\n",
        "    \n",
        "    fig_batch.add_trace(go.Bar(\n",
        "        name='Legitimate Emails',\n",
        "        y=batch_features['Feature'],\n",
        "        x=batch_features['Legitimate_Mean'],\n",
        "        orientation='h',\n",
        "        marker_color='#2ecc71',\n",
        "        text=[f'{v:.3f}' for v in batch_features['Legitimate_Mean']],\n",
        "        textposition='auto',\n",
        "        hovertemplate='<b>%{y}</b><br>Legitimate: %{x:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig_batch.add_trace(go.Bar(\n",
        "        name='Phishing Emails',\n",
        "        y=batch_features['Feature'],\n",
        "        x=batch_features['Phishing_Mean'],\n",
        "        orientation='h',\n",
        "        marker_color='#e74c3c',\n",
        "        text=[f'{v:.3f}' for v in batch_features['Phishing_Mean']],\n",
        "        textposition='auto',\n",
        "        hovertemplate='<b>%{y}</b><br>Phishing: %{x:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig_batch.update_layout(\n",
        "        title=f'🔍 Feature Comparison - Batch {batch_idx + 1}/{num_batches} (Features {start_idx + 1}-{end_idx})',\n",
        "        xaxis_title='Mean Feature Value',\n",
        "        yaxis_title='Features',\n",
        "        barmode='group',\n",
        "        height=800,\n",
        "        width=1000,\n",
        "        template='plotly_white',\n",
        "        yaxis=dict(autorange=\"reversed\"),\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    filename = f\"{output_dir}/feature_comparison_all_batch{batch_idx + 1:02d}.html\"\n",
        "    fig_batch.write_html(filename)\n",
        "    print(f\"   ✅ Batch {batch_idx + 1}/{num_batches} saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 2: MI-SELECTED FEATURES COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🎯 SECTION 2: MI-SELECTED FEATURES COMPARISON\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Calculate Mutual Information\n",
        "print(\"   Calculating Mutual Information scores...\")\n",
        "mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n",
        "mi_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'MI_Score': mi_scores\n",
        "}).sort_values('MI_Score', ascending=False)\n",
        "\n",
        "# Select top features by MI (e.g., top 15)\n",
        "n_top_mi = 15\n",
        "top_mi_features = mi_df.head(n_top_mi)['Feature'].tolist()\n",
        "\n",
        "print(f\"✅ Selected top {n_top_mi} features by Mutual Information\")\n",
        "print(f\"\\n   Top 5 MI features:\")\n",
        "for i, row in mi_df.head(5).iterrows():\n",
        "    print(f\"   {i+1}. {row['Feature']}: MI={row['MI_Score']:.4f}\")\n",
        "\n",
        "# Get comparison data for MI features\n",
        "mi_feature_comparison = []\n",
        "\n",
        "for feat in top_mi_features:\n",
        "    legit_mean = X_train.loc[legit_indices, feat].mean()\n",
        "    phish_mean = X_train.loc[phish_indices, feat].mean()\n",
        "    diff = abs(phish_mean - legit_mean)\n",
        "    mi_score = mi_df[mi_df['Feature'] == feat]['MI_Score'].values[0]\n",
        "    \n",
        "    mi_feature_comparison.append({\n",
        "        'Feature': feat,\n",
        "        'Legitimate_Mean': legit_mean,\n",
        "        'Phishing_Mean': phish_mean,\n",
        "        'Difference': diff,\n",
        "        'MI_Score': mi_score\n",
        "    })\n",
        "\n",
        "mi_features_df = pd.DataFrame(mi_feature_comparison)\n",
        "mi_features_df = mi_features_df.sort_values('MI_Score', ascending=False)\n",
        "\n",
        "# Create MI features comparison chart\n",
        "fig_mi = go.Figure()\n",
        "\n",
        "fig_mi.add_trace(go.Bar(\n",
        "    name='Legitimate Emails',\n",
        "    y=mi_features_df['Feature'],\n",
        "    x=mi_features_df['Legitimate_Mean'],\n",
        "    orientation='h',\n",
        "    marker_color='#2ecc71',\n",
        "    text=[f'{v:.3f}' for v in mi_features_df['Legitimate_Mean']],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Legitimate: %{x:.4f}<br>MI Score: %{customdata:.4f}<extra></extra>',\n",
        "    customdata=mi_features_df['MI_Score']\n",
        "))\n",
        "\n",
        "fig_mi.add_trace(go.Bar(\n",
        "    name='Phishing Emails',\n",
        "    y=mi_features_df['Feature'],\n",
        "    x=mi_features_df['Phishing_Mean'],\n",
        "    orientation='h',\n",
        "    marker_color='#e74c3c',\n",
        "    text=[f'{v:.3f}' for v in mi_features_df['Phishing_Mean']],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Phishing: %{x:.4f}<br>MI Score: %{customdata:.4f}<extra></extra>',\n",
        "    customdata=mi_features_df['MI_Score']\n",
        "))\n",
        "\n",
        "fig_mi.update_layout(\n",
        "    title=f'🎯 Top {n_top_mi} Features by Mutual Information: Legitimate vs Phishing',\n",
        "    xaxis_title='Mean Feature Value',\n",
        "    yaxis_title='Features (Ranked by MI Score)',\n",
        "    barmode='group',\n",
        "    height=700,\n",
        "    width=1000,\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(autorange=\"reversed\"),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/feature_comparison_top_MI.html\"\n",
        "fig_mi.write_html(filename)\n",
        "print(f\"\\n✅ Top MI features chart saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 3: QUBO-SELECTED FEATURES COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "if 'selected_features' in locals() or 'selected_features' in globals():\n",
        "    print(\"\\n⚛️ SECTION 3: QUBO-SELECTED FEATURES COMPARISON\")\n",
        "    print(\"-\"*70)\n",
        "    \n",
        "    # Get comparison data for QUBO features\n",
        "    qubo_feature_comparison = []\n",
        "    \n",
        "    for feat in selected_features:\n",
        "        legit_mean = X_train.loc[legit_indices, feat].mean()\n",
        "        phish_mean = X_train.loc[phish_indices, feat].mean()\n",
        "        diff = abs(phish_mean - legit_mean)\n",
        "        \n",
        "        qubo_feature_comparison.append({\n",
        "            'Feature': feat,\n",
        "            'Legitimate_Mean': legit_mean,\n",
        "            'Phishing_Mean': phish_mean,\n",
        "            'Difference': diff\n",
        "        })\n",
        "    \n",
        "    qubo_features_df = pd.DataFrame(qubo_feature_comparison)\n",
        "    qubo_features_df = qubo_features_df.sort_values('Difference', ascending=False)\n",
        "    \n",
        "    print(f\"✅ Analyzed {len(selected_features)} QUBO-selected features\")\n",
        "    \n",
        "    # Create QUBO features comparison chart\n",
        "    fig_qubo = go.Figure()\n",
        "    \n",
        "    # Show top 15 or all if less\n",
        "    n_display = min(15, len(qubo_features_df))\n",
        "    display_qubo = qubo_features_df.head(n_display)\n",
        "    \n",
        "    fig_qubo.add_trace(go.Bar(\n",
        "        name='Legitimate Emails',\n",
        "        y=display_qubo['Feature'],\n",
        "        x=display_qubo['Legitimate_Mean'],\n",
        "        orientation='h',\n",
        "        marker_color='#2ecc71',\n",
        "        text=[f'{v:.3f}' for v in display_qubo['Legitimate_Mean']],\n",
        "        textposition='auto',\n",
        "        hovertemplate='<b>%{y}</b><br>Legitimate: %{x:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig_qubo.add_trace(go.Bar(\n",
        "        name='Phishing Emails',\n",
        "        y=display_qubo['Feature'],\n",
        "        x=display_qubo['Phishing_Mean'],\n",
        "        orientation='h',\n",
        "        marker_color='#e74c3c',\n",
        "        text=[f'{v:.3f}' for v in display_qubo['Phishing_Mean']],\n",
        "        textposition='auto',\n",
        "        hovertemplate='<b>%{y}</b><br>Phishing: %{x:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig_qubo.update_layout(\n",
        "        title=f'⚛️ QUBO-Selected Features: Legitimate vs Phishing (Top {n_display} by Difference)',\n",
        "        xaxis_title='Mean Feature Value',\n",
        "        yaxis_title='Features',\n",
        "        barmode='group',\n",
        "        height=700,\n",
        "        width=1000,\n",
        "        template='plotly_white',\n",
        "        yaxis=dict(autorange=\"reversed\"),\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    filename = f\"{output_dir}/feature_comparison_QUBO_selected.html\"\n",
        "    fig_qubo.write_html(filename)\n",
        "    print(f\"\\n✅ QUBO features chart saved: {filename}\")\n",
        "    \n",
        "    # If QUBO has many features, create full chart\n",
        "    if len(qubo_features_df) > 15:\n",
        "        fig_qubo_full = go.Figure()\n",
        "        \n",
        "        fig_qubo_full.add_trace(go.Bar(\n",
        "            name='Legitimate Emails',\n",
        "            y=qubo_features_df['Feature'],\n",
        "            x=qubo_features_df['Legitimate_Mean'],\n",
        "            orientation='h',\n",
        "            marker_color='#2ecc71',\n",
        "            text=[f'{v:.3f}' for v in qubo_features_df['Legitimate_Mean']],\n",
        "            textposition='auto'\n",
        "        ))\n",
        "        \n",
        "        fig_qubo_full.add_trace(go.Bar(\n",
        "            name='Phishing Emails',\n",
        "            y=qubo_features_df['Feature'],\n",
        "            x=qubo_features_df['Phishing_Mean'],\n",
        "            orientation='h',\n",
        "            marker_color='#e74c3c',\n",
        "            text=[f'{v:.3f}' for v in qubo_features_df['Phishing_Mean']],\n",
        "            textposition='auto'\n",
        "        ))\n",
        "        \n",
        "        fig_qubo_full.update_layout(\n",
        "            title=f'⚛️ All {len(selected_features)} QUBO-Selected Features: Legitimate vs Phishing',\n",
        "            xaxis_title='Mean Feature Value',\n",
        "            yaxis_title='Features',\n",
        "            barmode='group',\n",
        "            height=max(800, len(qubo_features_df) * 30),\n",
        "            width=1000,\n",
        "            template='plotly_white',\n",
        "            yaxis=dict(autorange=\"reversed\")\n",
        "        )\n",
        "        \n",
        "        filename = f\"{output_dir}/feature_comparison_QUBO_all.html\"\n",
        "        fig_qubo_full.write_html(filename)\n",
        "        print(f\"✅ All QUBO features chart saved: {filename}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠️  QUBO selected_features not found, skipping QUBO comparison\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 4: SUMMARY STATISTICS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📊 SECTION 4: SUMMARY STATISTICS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_data = {\n",
        "    'Category': ['All Features', f'Top {n_top_mi} MI Features'],\n",
        "    'Count': [len(all_features), n_top_mi],\n",
        "    'Avg Difference': [\n",
        "        all_features_df['Absolute_Difference'].mean(),\n",
        "        mi_features_df['Difference'].mean()\n",
        "    ],\n",
        "    'Max Difference': [\n",
        "        all_features_df['Absolute_Difference'].max(),\n",
        "        mi_features_df['Difference'].max()\n",
        "    ]\n",
        "}\n",
        "\n",
        "if 'selected_features' in locals() or 'selected_features' in globals():\n",
        "    summary_data['Category'].append('QUBO Selected')\n",
        "    summary_data['Count'].append(len(selected_features))\n",
        "    summary_data['Avg Difference'].append(qubo_features_df['Difference'].mean())\n",
        "    summary_data['Max Difference'].append(qubo_features_df['Difference'].max())\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"\\n\" + summary_df.to_string(index=False))\n",
        "\n",
        "# Save summary\n",
        "summary_df.to_csv(f\"{output_dir}/feature_comparison_summary.csv\", index=False)\n",
        "print(f\"\\n✅ Summary saved: {output_dir}/feature_comparison_summary.csv\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FEATURE COMPARISON COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📂 Output Directory: {output_dir}/\")\n",
        "print(\"\\n📊 Generated Files:\")\n",
        "print(f\"   • feature_comparison_top20.html (Top 20 features)\")\n",
        "print(f\"   • feature_comparison_all_batch01.html to batch{num_batches:02d}.html (All features)\")\n",
        "print(f\"   • feature_comparison_top_MI.html (Top {n_top_mi} MI features)\")\n",
        "if 'selected_features' in locals() or 'selected_features' in globals():\n",
        "    print(f\"   • feature_comparison_QUBO_selected.html (QUBO features)\")\n",
        "    if len(selected_features) > 15:\n",
        "        print(f\"   • feature_comparison_QUBO_all.html (All QUBO features)\")\n",
        "print(f\"   • feature_comparison_summary.csv (Summary statistics)\")\n",
        "\n",
        "print(\"\\n🌐 To view: Open any .html file in your web browser\")\n",
        "print(\"\\n🎯 Key Insights:\")\n",
        "print(f\"   • Total features analyzed: {len(all_features)}\")\n",
        "print(f\"   • Feature with largest difference: {all_features_df.iloc[0]['Feature']}\")\n",
        "print(f\"   • Difference: {all_features_df.iloc[0]['Absolute_Difference']:.3f}\")\n",
        "print(f\"   • Top MI feature: {mi_df.iloc[0]['Feature']} (MI={mi_df.iloc[0]['MI_Score']:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ed82d056",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ADVANCED EXPLAINABILITY & ERROR ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "❌ SECTION 1: ERROR ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "✅ Error analysis saved: visualization_outputs/advanced_01_error_analysis.html\n",
            "   Both correct: 1480 (94.57%)\n",
            "   SVM wrong, QSVM correct: 43\n",
            "   QSVM wrong, SVM correct: 40\n",
            "   Both wrong: 2\n",
            "✅ FP/FN analysis saved: visualization_outputs/advanced_02_false_pos_neg.html\n",
            "\n",
            "📊 Error Types:\n",
            "   SVM  - False Positives: 0, False Negatives: 42\n",
            "   QSVM - False Positives: 17, False Negatives: 28\n",
            "\n",
            "🔍 SECTION 2: FEATURE CONTRIBUTION TO ERRORS\n",
            "----------------------------------------------------------------------\n",
            "✅ Error features saved: visualization_outputs/advanced_03_error_features.html\n",
            "   Features with largest difference in error cases:\n",
            "   1. content_entropy: 0.0987\n",
            "   2. web_js_len: 0.0732\n",
            "   3. url_num_hyphens: 0.0345\n",
            "   4. url_suspicious_chars: 0.0260\n",
            "   5. domain_contains_numbers: 0.0107\n",
            "\n",
            "⚛️ SECTION 3: QUANTUM CIRCUIT INSIGHTS\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "🔬 Quantum Circuit Properties:\n",
            "   Qubits: 6\n",
            "   Circuit Depth: 1\n",
            "   Number of Parameters: 6\n",
            "   Entanglement: linear\n",
            "   Repetitions: 1\n",
            "✅ Circuit insights saved: visualization_outputs/advanced_04_quantum_circuit.html\n",
            "\n",
            "🤝 SECTION 4: MODEL AGREEMENT ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "✅ Agreement analysis saved: visualization_outputs/advanced_05_model_agreement.html\n",
            "   Overall agreement: 94.70%\n",
            "   Legitimate class: 97.88%\n",
            "   Phishing class: 91.37%\n",
            "\n",
            "🎯 SECTION 5: DIFFICULT SAMPLES ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "✅ Difficult samples saved: visualization_outputs/advanced_06_difficult_samples.html\n",
            "   SVM: 20 samples with high prediction variance\n",
            "   QSVM: 20 samples with high prediction variance\n",
            "   Mean variance - SVM: 0.0018, QSVM: 0.0130\n",
            "\n",
            "📡 SECTION 6: COMPARATIVE PERFORMANCE RADAR\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "📊 Calculated Metrics:\n",
            "   SVM  - Specificity: 1.0000, FNR: 0.0549 (42 false negatives)\n",
            "   QSVM - Specificity: 0.9788, FNR: 0.0366 (28 false negatives)\n",
            "✅ Radar chart saved: visualization_outputs/advanced_07_performance_radar.html\n",
            "\n",
            "======================================================================\n",
            "✅ ADVANCED EXPLAINABILITY COMPLETE\n",
            "======================================================================\n",
            "\n",
            "📂 Output Directory: visualization_outputs/\n",
            "\n",
            "📊 Generated Advanced Visualizations:\n",
            "   advanced_01_error_analysis.html\n",
            "   advanced_02_false_pos_neg.html\n",
            "   advanced_03_error_features.html\n",
            "   advanced_04_quantum_circuit.html\n",
            "   advanced_05_model_agreement.html\n",
            "   advanced_06_difficult_samples.html\n",
            "   advanced_07_performance_radar.html\n",
            "\n",
            "💡 Key Explainability Insights:\n",
            "   • Models agree on 94.6% of predictions\n",
            "   • Challenging cases where both fail: 2 samples\n",
            "   • Most error-associated feature: content_entropy\n",
            "   • Quantum circuit uses 6 qubits at depth 1\n",
            "\n",
            "🎯 These visualizations help understand:\n",
            "   → Where models make mistakes\n",
            "   → Why models disagree\n",
            "   → Which samples are inherently difficult\n",
            "   → How quantum circuits encode information\n",
            "   → Feature importance in predictions\n"
          ]
        }
      ],
      "source": [
        "# ADVANCED EXPLAINABILITY & ERROR ANALYSIS - FIXED VERSION\n",
        "# Saves all plots as HTML files\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ADVANCED EXPLAINABILITY & ERROR ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"visualization_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 1: ERROR ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n❌ SECTION 1: ERROR ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 1.1 Error Type Analysis\n",
        "svm_errors = (svm_final_pred != y_test.values)\n",
        "qsvm_errors = (qsvm_final_pred != y_test.values)\n",
        "\n",
        "# Categorize errors\n",
        "both_correct = (~svm_errors) & (~qsvm_errors)\n",
        "both_wrong = svm_errors & qsvm_errors\n",
        "svm_only_wrong = svm_errors & (~qsvm_errors)\n",
        "qsvm_only_wrong = (~svm_errors) & qsvm_errors\n",
        "\n",
        "error_counts = {\n",
        "    'Both Correct': both_correct.sum(),\n",
        "    'SVM Wrong,\\nQSVM Correct': qsvm_only_wrong.sum(),\n",
        "    'QSVM Wrong,\\nSVM Correct': svm_only_wrong.sum(),\n",
        "    'Both Wrong': both_wrong.sum()\n",
        "}\n",
        "\n",
        "fig_errors = go.Figure()\n",
        "\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c', '#95a5a6']\n",
        "\n",
        "fig_errors.add_trace(go.Bar(\n",
        "    x=list(error_counts.keys()),\n",
        "    y=list(error_counts.values()),\n",
        "    marker_color=colors,\n",
        "    text=list(error_counts.values()),\n",
        "    textposition='auto',\n",
        "    texttemplate='<b>%{text}</b><br>',\n",
        "    hovertemplate='<b>%{x}</b><br><extra></extra>'\n",
        "))\n",
        "\n",
        "fig_errors.update_layout(\n",
        "    title='❌ Error Analysis: Where Do Models Agree/Disagree?',\n",
        "    yaxis_title='Number of Samples',\n",
        "    height=500,\n",
        "    width=900,\n",
        "    template='plotly_white',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/advanced_01_error_analysis.html\"\n",
        "fig_errors.write_html(filename)\n",
        "print(f\"✅ Error analysis saved: {filename}\")\n",
        "\n",
        "print(f\"   Both correct: {error_counts['Both Correct']} ({error_counts['Both Correct']/len(y_test)*100:.2f}%)\")\n",
        "print(f\"   SVM wrong, QSVM correct: {qsvm_only_wrong.sum()}\")\n",
        "print(f\"   QSVM wrong, SVM correct: {svm_only_wrong.sum()}\")\n",
        "print(f\"   Both wrong: {both_wrong.sum()}\")\n",
        "\n",
        "\n",
        "# 1.2 False Positive vs False Negative Analysis\n",
        "svm_fp = ((svm_final_pred == 1) & (y_test.values == 0)).sum()\n",
        "svm_fn = ((svm_final_pred == 0) & (y_test.values == 1)).sum()\n",
        "qsvm_fp = ((qsvm_final_pred == 1) & (y_test.values == 0)).sum()\n",
        "qsvm_fn = ((qsvm_final_pred == 0) & (y_test.values == 1)).sum()\n",
        "\n",
        "fig_fpfn = go.Figure()\n",
        "\n",
        "fig_fpfn.add_trace(go.Bar(\n",
        "    name='False Positives',\n",
        "    x=['SVM', 'QSVM'],\n",
        "    y=[svm_fp, qsvm_fp],\n",
        "    marker_color='#e67e22',\n",
        "    text=[svm_fp, qsvm_fp],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{x}</b><br>False Positives: %{y}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fpfn.add_trace(go.Bar(\n",
        "    name='False Negatives',\n",
        "    x=['SVM', 'QSVM'],\n",
        "    y=[svm_fn, qsvm_fn],\n",
        "    marker_color='#e74c3c',\n",
        "    text=[svm_fn, qsvm_fn],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{x}</b><br>False Negatives: %{y}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fpfn.update_layout(\n",
        "    title='🚨 False Positives vs False Negatives',\n",
        "    yaxis_title='Error Count',\n",
        "    barmode='group',\n",
        "    height=500,\n",
        "    width=800,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/advanced_02_false_pos_neg.html\"\n",
        "fig_fpfn.write_html(filename)\n",
        "print(f\"✅ FP/FN analysis saved: {filename}\")\n",
        "\n",
        "print(f\"\\n📊 Error Types:\")\n",
        "print(f\"   SVM  - False Positives: {svm_fp}, False Negatives: {svm_fn}\")\n",
        "print(f\"   QSVM - False Positives: {qsvm_fp}, False Negatives: {qsvm_fn}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 2: FEATURE CONTRIBUTION TO ERRORS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🔍 SECTION 2: FEATURE CONTRIBUTION TO ERRORS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Compare feature values for correct vs incorrect predictions\n",
        "error_indices = np.where(qsvm_errors)[0]\n",
        "correct_indices = np.where(~qsvm_errors)[0]\n",
        "\n",
        "# Calculate mean feature values\n",
        "features_error = X_test_scaled[selected_features].iloc[error_indices].mean()\n",
        "features_correct = X_test_scaled[selected_features].iloc[correct_indices].mean()\n",
        "features_diff = (features_error - features_correct).abs().sort_values(ascending=False)\n",
        "\n",
        "fig_error_feat = go.Figure()\n",
        "\n",
        "fig_error_feat.add_trace(go.Bar(\n",
        "    x=features_diff.head(10).values,\n",
        "    y=features_diff.head(10).index,\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color=features_diff.head(10).values,\n",
        "        colorscale='Reds',\n",
        "        showscale=True,\n",
        "        colorbar=dict(title=\"Difference\")\n",
        "    ),\n",
        "    text=[f'{v:.3f}' for v in features_diff.head(10).values],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{y}</b><br>Difference: %{x:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_error_feat.update_layout(\n",
        "    title='🔍 Features Most Associated with Errors ',\n",
        "    xaxis_title='Mean Feature Value Difference (Error vs Correct)',\n",
        "    yaxis_title='Features',\n",
        "    height=600,\n",
        "    width=900,\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(autorange=\"reversed\")\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/advanced_03_error_features.html\"\n",
        "fig_error_feat.write_html(filename)\n",
        "print(f\"✅ Error features saved: {filename}\")\n",
        "\n",
        "print(f\"   Features with largest difference in error cases:\")\n",
        "for i, (feat, diff) in enumerate(features_diff.head(5).items(), 1):\n",
        "    print(f\"   {i}. {feat}: {diff:.4f}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 3: QUANTUM CIRCUIT INSIGHTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n⚛️ SECTION 3: QUANTUM CIRCUIT INSIGHTS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "print(f\"\\n🔬 Quantum Circuit Properties:\")\n",
        "print(f\"   Qubits: {feature_map.num_qubits}\")\n",
        "print(f\"   Circuit Depth: {feature_map.depth()}\")\n",
        "print(f\"   Number of Parameters: {feature_map.num_parameters}\")\n",
        "print(f\"   Entanglement: {feature_map.entanglement}\")\n",
        "print(f\"   Repetitions: {feature_map.reps}\")\n",
        "\n",
        "# Circuit complexity visualization\n",
        "fig_circuit = go.Figure()\n",
        "\n",
        "fig_circuit.add_trace(go.Indicator(\n",
        "    mode=\"number+gauge\",\n",
        "    value=feature_map.num_qubits,\n",
        "    domain={'x': [0, 0.3], 'y': [0, 1]},\n",
        "    title={'text': \"Qubits\"},\n",
        "    gauge={'axis': {'range': [None, 20]},\n",
        "           'bar': {'color': \"#3498db\"}}\n",
        "))\n",
        "\n",
        "fig_circuit.add_trace(go.Indicator(\n",
        "    mode=\"number+gauge\",\n",
        "    value=feature_map.depth(),\n",
        "    domain={'x': [0.35, 0.65], 'y': [0, 1]},\n",
        "    title={'text': \"Circuit<br>Depth\"},\n",
        "    gauge={'axis': {'range': [None, 100]},\n",
        "           'bar': {'color': \"#e74c3c\"}}\n",
        "))\n",
        "\n",
        "fig_circuit.add_trace(go.Indicator(\n",
        "    mode=\"number+gauge\",\n",
        "    value=feature_map.num_parameters,\n",
        "    domain={'x': [0.7, 1], 'y': [0, 1]},\n",
        "    title={'text': \"Parameters\"},\n",
        "    gauge={'axis': {'range': [None, 50]},\n",
        "           'bar': {'color': \"#2ecc71\"}}\n",
        "))\n",
        "\n",
        "fig_circuit.update_layout(\n",
        "    title='⚛️ Quantum Circuit Complexity',\n",
        "    height=400,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/advanced_04_quantum_circuit.html\"\n",
        "fig_circuit.write_html(filename)\n",
        "print(f\"✅ Circuit insights saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 4: MODEL AGREEMENT ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🤝 SECTION 4: MODEL AGREEMENT ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Agreement matrix\n",
        "agreement = (svm_final_pred == qsvm_final_pred)\n",
        "agreement_by_class = pd.DataFrame({\n",
        "    'Actual': y_test.values,\n",
        "    'Agreement': agreement\n",
        "}).groupby('Actual')['Agreement'].agg(['sum', 'count', 'mean'])\n",
        "\n",
        "fig_agreement = go.Figure()\n",
        "\n",
        "class_names = ['Legitimate', 'Phishing']\n",
        "\n",
        "fig_agreement.add_trace(go.Bar(\n",
        "    x=class_names,\n",
        "    y=[agreement_by_class.loc[0, 'mean'], agreement_by_class.loc[1, 'mean']],\n",
        "    marker_color=['#2ecc71', '#e74c3c'],\n",
        "    text=[f\"{agreement_by_class.loc[0, 'mean']:.2%}\", \n",
        "          f\"{agreement_by_class.loc[1, 'mean']:.2%}\"],\n",
        "    textposition='auto',\n",
        "    hovertemplate='<b>%{x}</b><br>Agreement: %{y:.2%}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_agreement.update_layout(\n",
        "    title='🤝 SVM-QSVM Agreement Rate by Class',\n",
        "    yaxis_title='Agreement Rate',\n",
        "    yaxis=dict(range=[0, 1], tickformat='.0%'),\n",
        "    height=500,\n",
        "    width=800,\n",
        "    template='plotly_white',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/advanced_05_model_agreement.html\"\n",
        "fig_agreement.write_html(filename)\n",
        "print(f\"✅ Agreement analysis saved: {filename}\")\n",
        "\n",
        "print(f\"   Overall agreement: {agreement.mean():.2%}\")\n",
        "print(f\"   Legitimate class: {agreement_by_class.loc[0, 'mean']:.2%}\")\n",
        "print(f\"   Phishing class: {agreement_by_class.loc[1, 'mean']:.2%}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 5: DIFFICULT SAMPLES ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🎯 SECTION 5: DIFFICULT SAMPLES ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Calculate how many models disagreed for each sample\n",
        "svm_ensemble = np.array(svm_preds_list).T\n",
        "qsvm_ensemble = np.array(qsvm_preds_list).T\n",
        "\n",
        "# Variance in predictions (measure of difficulty)\n",
        "svm_variance = np.var(svm_ensemble, axis=1)\n",
        "qsvm_variance = np.var(qsvm_ensemble, axis=1)\n",
        "\n",
        "# Identify most difficult samples (high variance)\n",
        "svm_difficult = np.argsort(svm_variance)[-20:]  # Top 20 most difficult\n",
        "qsvm_difficult = np.argsort(qsvm_variance)[-20:]\n",
        "\n",
        "fig_difficult = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('SVM Prediction Variance', 'QSVM Prediction Variance')\n",
        ")\n",
        "\n",
        "fig_difficult.add_trace(\n",
        "    go.Histogram(\n",
        "        x=svm_variance,\n",
        "        marker_color='#3498db',\n",
        "        nbinsx=50,\n",
        "        name='SVM',\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig_difficult.add_trace(\n",
        "    go.Histogram(\n",
        "        x=qsvm_variance,\n",
        "        marker_color='#e74c3c',\n",
        "        nbinsx=50,\n",
        "        name='QSVM',\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig_difficult.update_layout(\n",
        "    title_text='🎯 Sample Difficulty Distribution (Batch Prediction Variance)',\n",
        "    height=500,\n",
        "    width=1000,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "fig_difficult.update_xaxes(title_text=\"Variance\", row=1, col=1)\n",
        "fig_difficult.update_xaxes(title_text=\"Variance\", row=1, col=2)\n",
        "fig_difficult.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
        "\n",
        "filename = f\"{output_dir}/advanced_06_difficult_samples.html\"\n",
        "fig_difficult.write_html(filename)\n",
        "print(f\"✅ Difficult samples saved: {filename}\")\n",
        "\n",
        "print(f\"   SVM: {len(svm_difficult)} samples with high prediction variance\")\n",
        "print(f\"   QSVM: {len(qsvm_difficult)} samples with high prediction variance\")\n",
        "print(f\"   Mean variance - SVM: {svm_variance.mean():.4f}, QSVM: {qsvm_variance.mean():.4f}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 6: COMPARATIVE PERFORMANCE RADAR\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📡 SECTION 6: COMPARATIVE PERFORMANCE RADAR\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Calculate all metrics\n",
        "svm_metrics = precision_recall_fscore_support(y_test, svm_final_pred, average='weighted')\n",
        "qsvm_metrics = precision_recall_fscore_support(y_test, qsvm_final_pred, average='weighted')\n",
        "\n",
        "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'FNR (inverted)']\n",
        "\n",
        "# Calculate specificity, FP, FN\n",
        "svm_tn = ((svm_final_pred == 0) & (y_test.values == 0)).sum()\n",
        "svm_fp = ((svm_final_pred == 1) & (y_test.values == 0)).sum()\n",
        "svm_tp = ((svm_final_pred == 1) & (y_test.values == 1)).sum()\n",
        "svm_fn = ((svm_final_pred == 0) & (y_test.values == 1)).sum()\n",
        "svm_spec = svm_tn / (svm_tn + svm_fp)\n",
        "svm_fnr = svm_fn / (svm_fn + svm_tp)  # False Negative Rate\n",
        "svm_fnr_inverted = 1 - svm_fnr  # Invert so higher is better on radar\n",
        "\n",
        "qsvm_tn = ((qsvm_final_pred == 0) & (y_test.values == 0)).sum()\n",
        "qsvm_fp = ((qsvm_final_pred == 1) & (y_test.values == 0)).sum()\n",
        "qsvm_tp = ((qsvm_final_pred == 1) & (y_test.values == 1)).sum()\n",
        "qsvm_fn = ((qsvm_final_pred == 0) & (y_test.values == 1)).sum()\n",
        "qsvm_spec = qsvm_tn / (qsvm_tn + qsvm_fp)\n",
        "qsvm_fnr = qsvm_fn / (qsvm_fn + qsvm_tp)  # False Negative Rate\n",
        "qsvm_fnr_inverted = 1 - qsvm_fnr  # Invert so higher is better on radar\n",
        "\n",
        "svm_values = [accuracy_score(y_test, svm_final_pred), \n",
        "              svm_metrics[0], svm_metrics[1], svm_metrics[2], svm_spec, svm_fnr_inverted]\n",
        "qsvm_values = [accuracy_score(y_test, qsvm_final_pred), \n",
        "               qsvm_metrics[0], qsvm_metrics[1], qsvm_metrics[2], qsvm_spec, qsvm_fnr_inverted]\n",
        "\n",
        "print(f\"\\n📊 Calculated Metrics:\")\n",
        "print(f\"   SVM  - Specificity: {svm_spec:.4f}, FNR: {svm_fnr:.4f} ({svm_fn} false negatives)\")\n",
        "print(f\"   QSVM - Specificity: {qsvm_spec:.4f}, FNR: {qsvm_fnr:.4f} ({qsvm_fn} false negatives)\")\n",
        "\n",
        "fig_radar = go.Figure()\n",
        "\n",
        "fig_radar.add_trace(go.Scatterpolar(\n",
        "    r=svm_values,\n",
        "    theta=categories,\n",
        "    fill='toself',\n",
        "    name='Classical SVM',\n",
        "    line_color='#3498db',\n",
        "    fillcolor='rgba(52, 152, 219, 0.3)'\n",
        "))\n",
        "\n",
        "fig_radar.add_trace(go.Scatterpolar(\n",
        "    r=qsvm_values,\n",
        "    theta=categories,\n",
        "    fill='toself',\n",
        "    name='Quantum SVM',\n",
        "    line_color='#e74c3c',\n",
        "    fillcolor='rgba(231, 76, 60, 0.3)'\n",
        "))\n",
        "\n",
        "fig_radar.update_layout(\n",
        "    polar=dict(\n",
        "        radialaxis=dict(\n",
        "            visible=True,\n",
        "            range=[0.85, 1.0]\n",
        "        )\n",
        "    ),\n",
        "    title='📡 Comprehensive Performance Radar Chart',\n",
        "    height=600,\n",
        "    width=800,\n",
        "    template='plotly_white',\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "filename = f\"{output_dir}/advanced_07_performance_radar.html\"\n",
        "fig_radar.write_html(filename)\n",
        "print(f\"✅ Radar chart saved: {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ ADVANCED EXPLAINABILITY COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📂 Output Directory: {output_dir}/\")\n",
        "print(\"\\n📊 Generated Advanced Visualizations:\")\n",
        "print(\"   advanced_01_error_analysis.html\")\n",
        "print(\"   advanced_02_false_pos_neg.html\")\n",
        "print(\"   advanced_03_error_features.html\")\n",
        "print(\"   advanced_04_quantum_circuit.html\")\n",
        "print(\"   advanced_05_model_agreement.html\")\n",
        "print(\"   advanced_06_difficult_samples.html\")\n",
        "print(\"   advanced_07_performance_radar.html\")\n",
        "\n",
        "print(\"\\n💡 Key Explainability Insights:\")\n",
        "print(f\"   • Models agree on {error_counts['Both Correct']/len(y_test)*100:.1f}% of predictions\")\n",
        "print(f\"   • Challenging cases where both fail: {both_wrong.sum()} samples\")\n",
        "print(f\"   • Most error-associated feature: {features_diff.index[0]}\")\n",
        "print(f\"   • Quantum circuit uses {feature_map.num_qubits} qubits at depth {feature_map.depth()}\")\n",
        "\n",
        "print(\"\\n🎯 These visualizations help understand:\")\n",
        "print(\"   → Where models make mistakes\")\n",
        "print(\"   → Why models disagree\")\n",
        "print(\"   → Which samples are inherently difficult\")\n",
        "print(\"   → How quantum circuits encode information\")\n",
        "print(\"   → Feature importance in predictions\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f012b18c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CURSE OF DIMENSIONALITY - FINDING THE BREAKING POINT\n",
            "======================================================================\n",
            "\n",
            "📊 STEP 1: RANKING FEATURES BY IMPORTANCE\n",
            "----------------------------------------------------------------------\n",
            "   Calculating Mutual Information scores...\n",
            "✅ Features ranked by MI score\n",
            "\n",
            "   Top 10 features:\n",
            "   6. web_js_len: 0.6573\n",
            "   9. js_obfuscation_ratio: 0.5212\n",
            "   7. web_js_obf_len: 0.5198\n",
            "   29. content_num_scripts: 0.4950\n",
            "   23. content_entropy: 0.4723\n",
            "   24. domain_trust_score: 0.3692\n",
            "   34. email_domain_freq: 0.3241\n",
            "   5. web_https: 0.2769\n",
            "   30. content_suspicious_keywords: 0.2696\n",
            "   4. web_who_is: 0.2613\n",
            "\n",
            "🔵 STEP 2: TESTING CLASSICAL SVM (Incremental Features)\n",
            "----------------------------------------------------------------------\n",
            "   Testing from 1 to 30 features...\n",
            "   This will take a few minutes...\n",
            "\n",
            "   [ 1/30] Training with 1 features... Test Acc: 0.9738 (1.05s)\n",
            "   [ 2/30] Training with 2 features... Test Acc: 0.9738 (0.62s)\n",
            "   [ 3/30] Training with 3 features... Test Acc: 0.9738 (0.68s)\n",
            "   [ 4/30] Training with 4 features... Test Acc: 0.9738 (0.67s)\n",
            "   [ 5/30] Training with 5 features... Test Acc: 0.9719 (0.65s)\n",
            "   [ 6/30] Training with 6 features... Test Acc: 0.9923 (0.52s)\n",
            "   [ 7/30] Training with 7 features... Test Acc: 0.9911 (0.50s)\n",
            "   [ 8/30] Training with 8 features... Test Acc: 0.9911 (0.48s)\n",
            "   [ 9/30] Training with 9 features... Test Acc: 0.9917 (0.48s)\n",
            "   [10/30] Training with 10 features... Test Acc: 0.9898 (0.43s)\n",
            "   [11/30] Training with 11 features... Test Acc: 0.9904 (0.47s)\n",
            "   [12/30] Training with 12 features... Test Acc: 0.9904 (0.48s)\n",
            "   [13/30] Training with 13 features... Test Acc: 0.9911 (0.48s)\n",
            "   [14/30] Training with 14 features... Test Acc: 0.9904 (0.49s)\n",
            "   [15/30] Training with 15 features... Test Acc: 0.9917 (0.47s)\n",
            "   [16/30] Training with 16 features... Test Acc: 0.9917 (0.48s)\n",
            "   [17/30] Training with 17 features... Test Acc: 0.9911 (0.50s)\n",
            "   [18/30] Training with 18 features... Test Acc: 0.9911 (0.51s)\n",
            "   [19/30] Training with 19 features... Test Acc: 0.9911 (0.50s)\n",
            "   [20/30] Training with 20 features... Test Acc: 0.9898 (0.55s)\n",
            "   [21/30] Training with 21 features... Test Acc: 0.9904 (0.50s)\n",
            "   [22/30] Training with 22 features... Test Acc: 0.9904 (0.52s)\n",
            "   [23/30] Training with 23 features... Test Acc: 0.9911 (0.69s)\n",
            "   [24/30] Training with 24 features... Test Acc: 0.9917 (0.57s)\n",
            "   [25/30] Training with 25 features... Test Acc: 0.9917 (0.61s)\n",
            "   [26/30] Training with 26 features... Test Acc: 0.9911 (0.62s)\n",
            "   [27/30] Training with 27 features... Test Acc: 0.9911 (0.70s)\n",
            "   [28/30] Training with 28 features... Test Acc: 0.9911 (0.73s)\n",
            "   [29/30] Training with 29 features... Test Acc: 0.9911 (0.72s)\n",
            "   [30/30] Training with 30 features... Test Acc: 0.9911 (0.73s)\n",
            "\n",
            "✅ SVM Testing Complete!\n",
            "\n",
            "🎯 SVM Results:\n",
            "   Peak accuracy: 0.9923 at 6 features\n",
            "   Curse not observed in tested range\n",
            "\n",
            "📈 STEP 4: CREATING THE CLASSIC CURSE GRAPH\n",
            "----------------------------------------------------------------------\n",
            "✅ Classic curse graph saved: visualization_outputs/curse_of_dimensionality_CLASSIC.html\n",
            "\n",
            "📊 STEP 5: CREATING DETAILED ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "✅ Train vs Test chart saved: visualization_outputs/curse_train_vs_test.html\n",
            "✅ Training time chart saved: visualization_outputs/curse_training_time.html\n",
            "\n",
            "======================================================================\n",
            "✅ CURSE OF DIMENSIONALITY ANALYSIS COMPLETE\n",
            "======================================================================\n",
            "\n",
            "🎯 CLASSICAL SVM:\n",
            "   ✅ Optimal: 6 features\n",
            "   ✅ Peak Accuracy: 0.9923\n",
            "   📊 Recommendation: Use 6 features\n",
            "\n",
            "📁 Generated Files:\n",
            "   • curse_of_dimensionality_CLASSIC.html (Main graph)\n",
            "   • curse_train_vs_test.html\n",
            "   • curse_training_time.html\n",
            "\n",
            "💡 ANSWER TO YOUR QUESTION:\n",
            "   For SVM: Use maximum 6 features before curse hits\n",
            "\n",
            "   This is where adding more features STOPS helping!\n",
            "\n",
            "✅ Results saved to CSV files\n"
          ]
        }
      ],
      "source": [
        "# CURSE OF DIMENSIONALITY - FINDING THE BREAKING POINT\n",
        "# Incrementally add features and find when accuracy DROPS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CURSE OF DIMENSIONALITY - FINDING THE BREAKING POINT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create output directory\n",
        "import os\n",
        "output_dir = \"visualization_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: RANK FEATURES BY IMPORTANCE\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📊 STEP 1: RANKING FEATURES BY IMPORTANCE\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Calculate Mutual Information\n",
        "print(\"   Calculating Mutual Information scores...\")\n",
        "mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n",
        "mi_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'MI_Score': mi_scores\n",
        "}).sort_values('MI_Score', ascending=False)\n",
        "\n",
        "print(f\"✅ Features ranked by MI score\")\n",
        "print(f\"\\n   Top 10 features:\")\n",
        "for i, row in mi_df.head(10).iterrows():\n",
        "    print(f\"   {i+1}. {row['Feature']}: {row['MI_Score']:.4f}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: INCREMENTAL FEATURE TESTING - CLASSICAL SVM\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n🔵 STEP 2: TESTING CLASSICAL SVM (Incremental Features)\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "max_features_to_test = min(30, len(mi_df))  # Test up to 30 features\n",
        "print(f\"   Testing from 1 to {max_features_to_test} features...\")\n",
        "print(f\"   This will take a few minutes...\\n\")\n",
        "\n",
        "svm_results = []\n",
        "\n",
        "for n_features in range(1, max_features_to_test + 1):\n",
        "    print(f\"   [{n_features:2d}/{max_features_to_test}] Training with {n_features} features...\", end=' ')\n",
        "    \n",
        "    # Get top N features\n",
        "    selected = mi_df.head(n_features)['Feature'].tolist()\n",
        "    \n",
        "    # Prepare data\n",
        "    X_train_subset = X_train_scaled[selected]\n",
        "    X_test_subset = X_test_scaled[selected]\n",
        "    \n",
        "    # Train SVM\n",
        "    start_time = time.time()\n",
        "    svm = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "    svm.fit(X_train_subset, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    \n",
        "    # Evaluate\n",
        "    train_acc = svm.score(X_train_subset, y_train)\n",
        "    test_acc = svm.score(X_test_subset, y_test)\n",
        "    \n",
        "    svm_results.append({\n",
        "        'n_features': n_features,\n",
        "        'train_accuracy': train_acc,\n",
        "        'test_accuracy': test_acc,\n",
        "        'gap': train_acc - test_acc,\n",
        "        'train_time': train_time\n",
        "    })\n",
        "    \n",
        "    print(f\"Test Acc: {test_acc:.4f} ({train_time:.2f}s)\")\n",
        "\n",
        "svm_df = pd.DataFrame(svm_results)\n",
        "\n",
        "# Find optimal and breaking points for SVM\n",
        "svm_peak_idx = svm_df['test_accuracy'].idxmax()\n",
        "svm_optimal = svm_df.iloc[svm_peak_idx]['n_features']\n",
        "svm_peak_acc = svm_df.iloc[svm_peak_idx]['test_accuracy']\n",
        "\n",
        "print(f\"\\n✅ SVM Testing Complete!\")\n",
        "print(f\"\\n🎯 SVM Results:\")\n",
        "print(f\"   Peak accuracy: {svm_peak_acc:.4f} at {int(svm_optimal)} features\")\n",
        "\n",
        "# Find where accuracy starts consistently dropping\n",
        "svm_threshold = svm_peak_acc - 0.005  # 0.5% drop threshold\n",
        "svm_drop_point = None\n",
        "for idx in range(svm_peak_idx, len(svm_df)):\n",
        "    if svm_df.iloc[idx]['test_accuracy'] < svm_threshold:\n",
        "        svm_drop_point = svm_df.iloc[idx]['n_features']\n",
        "        break\n",
        "\n",
        "if svm_drop_point:\n",
        "    print(f\"   Curse starts: After {svm_drop_point} features (accuracy drops)\")\n",
        "else:\n",
        "    print(f\"   Curse not observed in tested range\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: THE CLASSIC CURSE OF DIMENSIONALITY GRAPH\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📈 STEP 4: CREATING THE CLASSIC CURSE GRAPH\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# SVM curve\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=svm_df['n_features'],\n",
        "    y=svm_df['test_accuracy'],\n",
        "    mode='lines+markers',\n",
        "    name='Classical SVM',\n",
        "    line=dict(color='#3498db', width=4),\n",
        "    marker=dict(size=10, symbol='circle'),\n",
        "    hovertemplate='<b>SVM: %{x} features</b><br>Test Acc: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "\n",
        "\n",
        "# Mark SVM optimal point\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[svm_optimal],\n",
        "    y=[svm_peak_acc],\n",
        "    mode='markers',\n",
        "    name=f'SVM Peak ({int(svm_optimal)} features)',\n",
        "    marker=dict(size=20, color='gold', symbol='star', line=dict(color='black', width=2)),\n",
        "    hovertemplate=f'<b>SVM OPTIMAL</b><br>{int(svm_optimal)} features<br>Acc: {svm_peak_acc:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "\n",
        "# Add curse of dimensionality annotation\n",
        "if svm_drop_point:\n",
        "    fig.add_vline(\n",
        "        x=svm_drop_point,\n",
        "        line_dash=\"dash\",\n",
        "        line_color=\"red\",\n",
        "        line_width=2,\n",
        "        annotation_text=f\"⚠️ Curse Begins<br>({svm_drop_point} features)\",\n",
        "        annotation_position=\"top\"\n",
        "    )\n",
        "\n",
        "# Add optimal zone shading\n",
        "fig.add_vrect(\n",
        "    x0=max(1, svm_optimal - 2),\n",
        "    x1=svm_optimal + 2,\n",
        "    fillcolor=\"green\",\n",
        "    opacity=0.1,\n",
        "    layer=\"below\",\n",
        "    line_width=0,\n",
        "    annotation_text=\"Optimal Zone\",\n",
        "    annotation_position=\"top left\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': '📈 THE CURSE OF DIMENSIONALITY<br><sub>Test Accuracy vs Number of Features</sub>',\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'font': {'size': 24}\n",
        "    },\n",
        "    xaxis_title='Number of Features',\n",
        "    yaxis_title='Test Accuracy',\n",
        "    xaxis=dict(\n",
        "        tickmode='linear',\n",
        "        tick0=1,\n",
        "        dtick=1,\n",
        "        gridcolor='lightgray'\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        range=[min(svm_df['test_accuracy'].min(), 0.85), 1.0],\n",
        "        gridcolor='lightgray'\n",
        "    ),\n",
        "    height=700,\n",
        "    width=1200,\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"v\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=0.02,\n",
        "        xanchor=\"right\",\n",
        "        x=0.98,\n",
        "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
        "        bordercolor=\"black\",\n",
        "        borderwidth=1\n",
        "    ),\n",
        "    font=dict(size=14)\n",
        ")\n",
        "\n",
        "filename_curse = f\"{output_dir}/curse_of_dimensionality_CLASSIC.html\"\n",
        "fig.write_html(filename_curse)\n",
        "print(f\"✅ Classic curse graph saved: {filename_curse}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: DETAILED ANALYSIS CHARTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📊 STEP 5: CREATING DETAILED ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# 5.1 Train vs Test Accuracy (Overfitting Detection)\n",
        "fig_train_test = go.Figure()\n",
        "\n",
        "# SVM Train\n",
        "fig_train_test.add_trace(go.Scatter(\n",
        "    x=svm_df['n_features'],\n",
        "    y=svm_df['train_accuracy'],\n",
        "    mode='lines',\n",
        "    name='SVM Train',\n",
        "    line=dict(color='#3498db', width=2, dash='dash'),\n",
        "    showlegend=True\n",
        "))\n",
        "\n",
        "# SVM Test\n",
        "fig_train_test.add_trace(go.Scatter(\n",
        "    x=svm_df['n_features'],\n",
        "    y=svm_df['test_accuracy'],\n",
        "    mode='lines+markers',\n",
        "    name='SVM Test',\n",
        "    line=dict(color='#3498db', width=4),\n",
        "    marker=dict(size=8),\n",
        "    showlegend=True\n",
        "))\n",
        "\n",
        "\n",
        "fig_train_test.update_layout(\n",
        "    title='📊 Train vs Test Accuracy (Overfitting Analysis)',\n",
        "    xaxis_title='Number of Features',\n",
        "    yaxis_title='Accuracy',\n",
        "    height=600,\n",
        "    width=1000,\n",
        "    template='plotly_white',\n",
        "    legend=dict(x=0.7, y=0.15)\n",
        ")\n",
        "\n",
        "filename_train_test = f\"{output_dir}/curse_train_vs_test.html\"\n",
        "fig_train_test.write_html(filename_train_test)\n",
        "print(f\"✅ Train vs Test chart saved: {filename_train_test}\")\n",
        "\n",
        "\n",
        "# 5.2 Training Time Analysis\n",
        "fig_time = go.Figure()\n",
        "\n",
        "fig_time.add_trace(go.Bar(\n",
        "    x=svm_df['n_features'],\n",
        "    y=svm_df['train_time'],\n",
        "    name='SVM',\n",
        "    marker_color='#3498db'\n",
        "))\n",
        "\n",
        "\n",
        "\n",
        "fig_time.update_layout(\n",
        "    title='⏱️ Training Time vs Number of Features',\n",
        "    xaxis_title='Number of Features',\n",
        "    yaxis_title='Training Time (seconds)',\n",
        "    yaxis_type='log',\n",
        "    height=500,\n",
        "    width=1000,\n",
        "    template='plotly_white',\n",
        "    barmode='group'\n",
        ")\n",
        "\n",
        "filename_time = f\"{output_dir}/curse_training_time.html\"\n",
        "fig_time.write_html(filename_time)\n",
        "print(f\"✅ Training time chart saved: {filename_time}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ CURSE OF DIMENSIONALITY ANALYSIS COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n🎯 CLASSICAL SVM:\")\n",
        "print(f\"   ✅ Optimal: {int(svm_optimal)} features\")\n",
        "print(f\"   ✅ Peak Accuracy: {svm_peak_acc:.4f}\")\n",
        "if svm_drop_point:\n",
        "    print(f\"   ⚠️  Curse begins: After {svm_drop_point} features\")\n",
        "    print(f\"   📊 Recommendation: Use {int(svm_optimal)} to {svm_drop_point-1} features\")\n",
        "else:\n",
        "    print(f\"   📊 Recommendation: Use {int(svm_optimal)} features\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\n📁 Generated Files:\")\n",
        "print(f\"   • curse_of_dimensionality_CLASSIC.html (Main graph)\")\n",
        "print(f\"   • curse_train_vs_test.html\")\n",
        "print(f\"   • curse_training_time.html\")\n",
        "\n",
        "print(f\"\\n💡 ANSWER TO YOUR QUESTION:\")\n",
        "print(f\"   For SVM: Use maximum {int(svm_optimal)} features before curse hits\")\n",
        "\n",
        "print(f\"\\n   This is where adding more features STOPS helping!\")\n",
        "\n",
        "# Save results to CSV\n",
        "svm_df.to_csv(f\"{output_dir}/curse_svm_results.csv\", index=False)\n",
        "\n",
        "print(f\"\\n✅ Results saved to CSV files\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
